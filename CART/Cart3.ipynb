{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cart endgame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and load the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../') \n",
    "from utils.loader import Loader\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.decomposition import PCA,TruncatedSVD\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.feature_selection import chi2\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import prince\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Loader.load_all()['original']\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"price_categ\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe some columns\n",
    "A more detailed version of the dataset can be found in the DataDescription.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.select_dtypes(include=['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_plot(arr, n_bins, title = \"hist_plot\", x_label = \"price\", y_label=\"frecuency\"):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.histplot(arr, kde=True, bins=n_bins)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_plot(data[data[\"fuelType\"]==\"Híbrido\"][\"price\"], n_bins=100, title='Price density curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precios_electricos = data[data[\"fuelType\"]==\"Eléctrico\"][\"price\"]\n",
    "print(precios_electricos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot(precios_electricos, notch=True, vert=True, patch_artist=True, showmeans=True)\n",
    "plt.title('Boxplot de Precios')\n",
    "plt.ylabel('Precio')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The related outliers were checked manually throught the data source, and we could confirmed that they are not outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = data['price'].quantile(0.25)\n",
    "Q2 = data['price'].quantile(0.5)  # Esta es la mediana\n",
    "Q3 = data['price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "upper_whisker = (Q3 + 1.5 * IQR)\n",
    "print(upper_whisker)\n",
    "\n",
    "data[data[\"fuelType\"] == \"Eléctrico\"][data[\"price\"]>upper_whisker][[\"price\", \"brand\"]].sort_values(by='price', ascending=False)\n",
    "#data = data[data[\"price\"]<upper_whisker]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate the DF in fuelType Categories\n",
    "\n",
    "We split the dataframe into the categories so in the PCA or CA, we don't discart columns because of the most popular classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_fuel_type(data:pd.DataFrame) -> dict:\n",
    "    ret={}\n",
    "    ret[\"Eléctrico\"] = data[data[\"fuelType\"] == \"Eléctrico\"]\n",
    "    ret[\"Combustion\"] = data[(data[\"fuelType\"] == \"Gasolina\") | (data[\"fuelType\"] == \"Diésel\")]\n",
    "    ret[\"Híbrido\"] = data[data[\"fuelType\"] == \"Híbrido\"]\n",
    "    ret[\"Híbrido enchufable\"] = data[data[\"fuelType\"] == \"Híbrido enchufable\"]\n",
    "    ret[\"Gas\"] = data[(data[\"fuelType\"] == \"Gas licuado (GLP)\") | (data[\"fuelType\"] == \"Gas natural (CNG)\")]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = split_fuel_type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data process functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_na_with_mode(df, column_name, inplace=False):\n",
    "    if column_name in df.columns:\n",
    "        mode_value = df[column_name].mode().iloc[0]\n",
    "        df[column_name] = df[column_name].fillna(mode_value, inplace=inplace)\n",
    "    else:\n",
    "        print(f\"La columna '{column_name}' no existe en el DataFrame.\")\n",
    "    return df\n",
    "\n",
    "def impute_with_linear_regression(data, x_columns, y_column):\n",
    "    df_with_target = data.dropna(subset=[y_column])\n",
    "    df_without_target = data[data[y_column].isna()]\n",
    "    \n",
    "    X_train = df_with_target[x_columns]\n",
    "    y_train = df_with_target[y_column]\n",
    "    X_test = df_without_target[x_columns]\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_train)\n",
    "    epsilon = np.finfo(np.float64).eps\n",
    "    mape = np.mean(np.abs((y_train - y_pred) / (y_train + epsilon))) * 100\n",
    "    print(f\"Regression mape {x_columns} -> {y_column}: {mape}%\")\n",
    "    if not X_test.empty:\n",
    "        predicted_values = model.predict(X_test)\n",
    "        data.loc[data[y_column].isna(), y_column] = predicted_values\n",
    "    return data\n",
    "\n",
    "def remove_redundand_columns(df:pd.DataFrame )->pd.DataFrame:\n",
    "    for column in df.columns: #Remove redundant columns\n",
    "        unique_values = df[column].dropna().unique() \n",
    "        if len(unique_values) == 1:\n",
    "            df = df.drop(column, axis=1)\n",
    "    return df\n",
    "\n",
    "def __impute_categorical_mode(df, X, Y):\n",
    "    # Agrupar por las columnas X y calcular el valor más común (moda) en la columna Y para cada grupo\n",
    "    modes = df.groupby(X,observed=False)[Y].agg(lambda x: x.dropna().mode()[0] if not x.dropna().empty else None, ).reset_index()\n",
    "    modes.rename(columns={Y: 'Mode'}, inplace=True)\n",
    "    \n",
    "    # Unir el DataFrame original con los modos encontrados para facilitar la imputación\n",
    "    df = df.merge(modes, on=X, how='left')\n",
    "    \n",
    "    # Imputar los valores NaN en Y usando el valor más común de su grupo\n",
    "    df[Y] = df.apply(lambda row: row['Mode'] if pd.isna(row[Y]) else row[Y], axis=1)\n",
    "\n",
    "    # Eliminar la columna auxiliar 'Mode' añadida para la imputación\n",
    "    df.drop('Mode', axis=1, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def impute_categorical_mode(df, X, Y):\n",
    "    for i in range(len(X)):\n",
    "        df = __impute_categorical_mode(df, X, Y)\n",
    "        X.pop(len(X)-1)\n",
    "    df[Y] = df[Y].fillna(\"unkown\") #If is a unique car\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CA (categorical_columns, col_x, col_y):\n",
    "    contingency_table = pd.crosstab(categorical_columns[col_x], categorical_columns[col_y])\n",
    "\n",
    "    P = contingency_table / contingency_table.values.sum()\n",
    "\n",
    "    # Calcular los perfiles de fila y columna (matrices D_r y D_c)\n",
    "    D_r = np.diag(1 / P.sum(axis=1))\n",
    "    D_c = np.diag(1 / P.sum(axis=0))\n",
    "\n",
    "    # Calcular la matriz S (correspondencia ajustada)\n",
    "    S = np.sqrt(D_r).dot(P).dot(np.sqrt(D_c))\n",
    "\n",
    "    # Aplicar SVD\n",
    "    svd = TruncatedSVD(n_components=2)\n",
    "    svd.fit(S)\n",
    "    row_coordinates = svd.transform(S)  # Coordenadas de las filas\n",
    "    col_coordinates = svd.components_.T  # Coordenadas de las columnas\n",
    "\n",
    "    # Visualización\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    for i, label in enumerate(contingency_table.index):\n",
    "        plt.scatter(row_coordinates[i, 0], row_coordinates[i, 1], color='blue')\n",
    "        plt.text(row_coordinates[i, 0], row_coordinates[i, 1], f'{label}', color='blue', ha='right', va='bottom')\n",
    "    for i, label in enumerate(contingency_table.columns):\n",
    "        plt.scatter(col_coordinates[i, 0], col_coordinates[i, 1], color='red', marker='^')\n",
    "        plt.text(col_coordinates[i, 0], col_coordinates[i, 1], f'{label}', color='red', ha='left', va='top')\n",
    "\n",
    "    plt.xlabel('Componente 1')\n",
    "    plt.ylabel('Componente 2')\n",
    "    plt.title('Gráfico de Análisis de Correspondencias')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_square_test(categorical_columns: pd.DataFrame, column_y: str):\n",
    "    encoded_df = categorical_columns.copy()\n",
    "    for col in categorical_columns.columns:\n",
    "        encoded_df[col] = label_encoder.fit_transform(encoded_df[col])\n",
    "\n",
    "    X = encoded_df.drop(columns=[column_y])\n",
    "    y = encoded_df[column_y]\n",
    "\n",
    "    # Realizar la prueba de chi-cuadrado\n",
    "    chi2_stat, p_values = chi2(X, y)\n",
    "\n",
    "    # Crear un DataFrame para mostrar los resultados\n",
    "    results = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Chi2 Stat': chi2_stat,\n",
    "        'p-value': p_values\n",
    "    })\n",
    "\n",
    "    # Ordenar los resultados por el valor p\n",
    "    results.sort_values('p-value', inplace=True)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(results['Feature'], results['p-value'], color='skyblue')\n",
    "    plt.xlabel('p-value')\n",
    "    plt.ylabel('Features')\n",
    "    plt.title('Chi-Square Test Results')\n",
    "    plt.gca().invert_yaxis()  # Invertir el eje y para que la característica con menor p-value esté arriba\n",
    "    plt.show()\n",
    "\n",
    "    # Mostrar el DataFrame de resultados\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_square_filter(categorical_columns: pd.DataFrame, column_y: str, p_value_filter: float) -> pd.DataFrame:\n",
    "    result = chi_square_test(categorical_columns=categorical_columns, column_y=column_y)\n",
    "    columns = list(result[ result[\"p-value\"] <= p_value_filter ][\"Feature\"])\n",
    "    columns.append(\"price_categ\")\n",
    "    return categorical_columns[ columns ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Electric cars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical variables selection Eléctrico\n",
    "Here we will perform PCA and use correlation matrix to select the most correlated numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_electric_numerical_columns(numerical_columns: pd.DataFrame) -> pd.DataFrame:\n",
    "    #fill the elemental columns that has a minor amount of missing data with the mode\n",
    "    numerical_columns = fill_na_with_mode(numerical_columns, \"dimensions.length\")\n",
    "    numerical_columns = fill_na_with_mode(numerical_columns, \"dimensions.height\")\n",
    "    numerical_columns = fill_na_with_mode(numerical_columns, \"electricFeatures.maximumBatteryKWH_kWh\")\n",
    "    numerical_columns = fill_na_with_mode(numerical_columns, \"electricFeatures.onboardCharger_kW\")\n",
    "    numerical_columns = fill_na_with_mode(numerical_columns, \"electricFeatures.range_KM\")\n",
    "\n",
    "    #fill the missing data witch regression, the parameters were based on the relation matrix \n",
    "    numerical_columns = impute_with_linear_regression(data=numerical_columns, x_columns=[\"dimensions.length\", \"dimensions.height\"], y_column=\"dimensions.width\")\n",
    "    numerical_columns = impute_with_linear_regression(data=numerical_columns, x_columns=[\"dimensions.length\", \"dimensions.height\", \"dimensions.width\"], y_column=\"trunkCapacityInLiters\")\n",
    "    numerical_columns = impute_with_linear_regression(data=numerical_columns, x_columns=[\"power_cv\", \"power_kw\"], y_column=\"maxSpeed\")\n",
    "    numerical_columns = impute_with_linear_regression(data=numerical_columns, x_columns=[\"power_cv\", \"power_kw\", \"maxSpeed\"], y_column=\"acceleration\")\n",
    "    numerical_columns = impute_with_linear_regression(data=numerical_columns, x_columns=[\"power_cv\", \"power_kw\", \"maxSpeed\"], y_column=\"acceleration\")\n",
    "    numerical_columns = impute_with_linear_regression(data=numerical_columns, x_columns=[\"Llantas_Diametro_cm\", \"power_kw\"], y_column=\"max_torque_nm\")\n",
    "    numerical_columns = impute_with_linear_regression(data=numerical_columns, x_columns=[\"electricFeatures.maximumBatteryKWH_kWh\", \"power_kw\", \"dimensions.length\", \"dimensions.height\", \"dimensions.width\"], y_column=\"electricFeatures.combinedConsumption_kWh/\")\n",
    "    numerical_columns = impute_with_linear_regression(data=numerical_columns, x_columns=[\"electricFeatures.maximumBatteryKWH_kWh\", \"electricFeatures.combinedConsumption_kWh/\", \"power_kw\"], y_column=\"electricFeatures.range_KM\")\n",
    "    numerical_columns.dropna(axis=1, inplace=True)\n",
    "    return numerical_columns\n",
    "\n",
    "def get_electric_numerical_columns (data: pd.DataFrame) -> pd.DataFrame:\n",
    "    numerical_columns = data.select_dtypes(include=['number'])\n",
    "    numerical_columns.drop(columns=[ \"car_id\", \"electricFeatures.maxPower_CV\"], inplace=True) # electricFeatures.maxPower_CV is = power_cv (Duplicated colums)\n",
    "\n",
    "    #if all the values of the numerical columns is 0, we remove the column\n",
    "    cols_to_drop = numerical_columns.columns[(numerical_columns == 0).all()]\n",
    "    numerical_columns = numerical_columns.drop(cols_to_drop, axis=1)\n",
    "\n",
    "    #Remove the column with all NAs\n",
    "    max_nans = 6586\n",
    "    thresh = numerical_columns.shape[0] - max_nans\n",
    "\n",
    "    numerical_columns.dropna(axis=1, thresh=thresh+1, inplace=True)\n",
    "    return fill_electric_numerical_columns(numerical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = get_electric_numerical_columns(data[\"Eléctrico\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = numerical_columns.corr()[\"price\"]\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df_scaled  = scaler.fit_transform(numerical_columns)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(df_scaled)\n",
    "df_pca = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biplot(score, coeff, labels=None):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    origin = [0, 0]  # Origen de las flechas\n",
    "\n",
    "    # Dibujar las flechas\n",
    "    for i in range(len(coeff)):\n",
    "        plt.arrow(origin[0], origin[1], coeff[i,0], coeff[i,1], color='r', alpha=0.5, head_width=0.05, head_length=0.1)\n",
    "        if labels is not None:\n",
    "            plt.text(coeff[i,0]*1.15, coeff[i,1]*1.15, labels[i], color='blue', ha='center', va='center')\n",
    "\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.title(\"Biplot\")\n",
    "    plt.grid(True)\n",
    "    plt.axhline(0, color='black',linewidth=0.5)\n",
    "    plt.axvline(0, color='black',linewidth=0.5)\n",
    "    plt.xlim(min(coeff[:,0])*1.2, max(coeff[:,0])*1.2)\n",
    "    plt.ylim(min(coeff[:,1])*1.2, max(coeff[:,1])*1.2)\n",
    "    plt.show()\n",
    "\n",
    "# Llamada a la función biplot\n",
    "biplot(principal_components, np.transpose(pca.components_[0:2, :]), labels=numerical_columns.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test CART regression trees with only numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = numerical_columns.drop(columns=\"price\")\n",
    "y = numerical_columns[\"price\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "tree_model = DecisionTreeRegressor(random_state=42)\n",
    "tree_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# Realizar predicciones sobre el conjunto de prueba\n",
    "y_pred = tree_model.predict(X_test)\n",
    "\n",
    "# Calcular el MAPE\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Electrico categorical variables\n",
    "Here we will perform CA and Chi2 test to select the best categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_electric_categorical_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ret = df.select_dtypes(include=['category'])\n",
    "    ret = ret.drop(columns=[\"environmentalLabel\"]) #All of the cars of this dataframes are electrical which implies 0 emission\n",
    "    ret = remove_redundand_columns(ret)\n",
    "    ret = impute_categorical_mode(df=ret, X=[\"brand\", \"model\"], Y=\"version\")\n",
    "    ret = impute_categorical_mode(df=ret, X=[\"brand\", \"model\"], Y=\"jato_classification\")\n",
    "    ret = impute_categorical_mode(df=ret, X=[\"brand\", \"model\", \"traction\"], Y=\"brakes\")\n",
    "    ret = impute_categorical_mode(df=ret, X=[\"brand\", \"model\", \"traction\",\"brakes\"], Y=\"front_suspension\")\n",
    "    ret = impute_categorical_mode(df=ret, X=[\"brand\", \"model\", \"traction\",\"brakes\"], Y=\"rear_suspension\")\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = get_electric_categorical_columns(data[\"Eléctrico\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_square_test(categorical_columns=categorical_columns, column_y=\"price_categ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CA(categorical_columns=categorical_columns, col_x=\"province\", col_y=\"price_categ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns[\"price_categ\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = chi_square_filter(categorical_columns, \"price_categ\", p_value_filter=0)\n",
    "categorical_columns.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test CART tree classifier with only categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(categorical_columns.columns)\n",
    "columns.remove(\"price_categ\")\n",
    "for col in columns:\n",
    "    categorical_columns[col] = label_encoder.fit_transform(categorical_columns[col])\n",
    "\n",
    "# Preparar los datos\n",
    "X = categorical_columns.drop(columns=[\"price_categ\"])\n",
    "print(categorical_columns[\"price_categ\"].value_counts())\n",
    "Y = categorical_columns[\"price_categ\"].apply(lambda x: Loader.encode_price_categ(x))\n",
    "print(max(Y))\n",
    "\n",
    "# Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42, stratify=Y)\n",
    "\n",
    "# Crear el modelo de árbol de decisión\n",
    "tree_model = DecisionTreeClassifier(random_state=42, criterion = \"entropy\")\n",
    "\n",
    "# Entrenar el modelo\n",
    "tree_model.fit(X_train, Y_train)\n",
    "\n",
    "# Predecir las etiquetas del conjunto de prueba\n",
    "Y_pred = tree_model.predict(X_test)\n",
    "\n",
    "# Calcular la precisión\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "print(f\"General MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "# Dibujar el árbol de decisión\n",
    "plot_tree(tree_model, \n",
    "          filled=True, \n",
    "          rounded=True, \n",
    "          class_names=X_train.columns, \n",
    "          feature_names=X.columns, \n",
    "          max_depth=3)  # Puedes ajustar la profundidad para una mejor visualización o quitar este parámetro para mostrar todo el árbol\n",
    "plt.title('Visualización del Árbol de Decisión')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Electric cars price regression with all the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns_full_nan(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    #Remove the column that only contain NAs\n",
    "    cols_to_drop = data.columns[data.isna().all()]\n",
    "    data = data.drop(cols_to_drop, axis=1)\n",
    "    return data\n",
    "\n",
    "def get_combustion_numerical_columns (data: pd.DataFrame) -> pd.DataFrame:\n",
    "    numerical_columns = data.select_dtypes(include=['number'])\n",
    "\n",
    "    #if all the values of the numerical columns is 0, we remove the column\n",
    "    cols_to_drop = numerical_columns.columns[(numerical_columns == 0).all()]\n",
    "    numerical_columns = numerical_columns.drop(cols_to_drop, axis=1)\n",
    "    return numerical_columns\n",
    "\n",
    "def fill_combustion_numerical_columns(numerical_columns: pd.DataFrame) -> pd.DataFrame:\n",
    "    cols_mode = ['displacement_liters','doors','seatingCapacity','number_of_cylinders','cubicCapacity',\"dimensions.length\",\"dimensions.height\",\"Llantas_Diametro_cm\",\"number_of_cylinders\",\"bore_diameter\",\"stroke_length\"]\n",
    "    #fill the elemental columns that has a minor amount of missing data with the mode\n",
    "    for col in cols_mode:\n",
    "        numerical_columns = fill_na_with_mode(numerical_columns, col)\n",
    "\n",
    "    #fill the missing data witch regression, the parameters were based on the relation matrix \n",
    "    numerical_columns = impute_with_linear_regression(data=numerical_columns, x_columns=[\"dimensions.length\", \"dimensions.height\"], y_column=\"dimensions.width\")\n",
    "    numerical_columns = impute_with_linear_regression(data=numerical_columns, x_columns=[\"dimensions.length\", \"dimensions.height\", \"dimensions.width\"], y_column=\"trunkCapacityInLiters\")\n",
    "    numerical_columns = impute_with_linear_regression(data=numerical_columns, x_columns=[\"power_cv\", \"power_kw\"], y_column=\"maxSpeed\")\n",
    "    numerical_columns = impute_with_linear_regression(data=numerical_columns, x_columns=[\"power_cv\", \"power_kw\", \"maxSpeed\"], y_column=\"acceleration\")\n",
    "    numerical_columns = impute_with_linear_regression(data=numerical_columns, x_columns=[\"power_cv\", \"power_kw\", \"maxSpeed\"], y_column=\"acceleration\")\n",
    "    numerical_columns = impute_with_linear_regression(data=numerical_columns, x_columns=[\"Llantas_Diametro_cm\", \"power_kw\"], y_column=\"max_torque_nm\")\n",
    "    numerical_columns = impute_with_linear_regression(data=numerical_columns, x_columns=[\"Llantas_Diametro_cm\", \"power_kw\"], y_column=\"rpm_max_torque\")\n",
    "    numerical_columns = impute_with_linear_regression(data=numerical_columns, x_columns=[\"Llantas_Diametro_cm\", \"power_kw\"], y_column=\"rpm_max_power\")\n",
    "    numerical_columns.dropna(axis=1, inplace=True)\n",
    "    return numerical_columns\n",
    "\n",
    "def get_combustion_categorical_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Select and print only the categorical columns\n",
    "    ret = df.select_dtypes(include=['category'])\n",
    "    \n",
    "    # Temporarily convert the column to strings to perform the replacement\n",
    "    ret['traction'] = ret['traction'].astype(str).replace({\"trasera\": \"trasero\", \"delantera\": \"delantero\"})\n",
    "    # Convert back to a categorical type\n",
    "    ret['traction'] = ret['traction'].astype('category')\n",
    "\n",
    "    \n",
    "    # Remove redundant columns if this function is defined\n",
    "    ret = remove_redundand_columns(ret)\n",
    "    return ret\n",
    "\n",
    "\n",
    "def fill_combustion_categorical_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    mode_cols = ['brakes','version','jato_classification']\n",
    "    for col in mode_cols:\n",
    "        df = fill_na_with_mode(df, col)\n",
    "    #df = impute_categorical_mode(df=df, X=[\"brand\", \"model\", \"traction\",\"brakes\"], Y=\"front_suspension\")\n",
    "    #df = impute_categorical_mode(df=df, X=[\"brand\", \"model\", \"traction\",\"brakes\"], Y=\"rear_suspension\")\n",
    "    return df\n",
    "\n",
    "def category_convert(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    cols_to_convert = df.select_dtypes(include=['object']).columns\n",
    "    for col in cols_to_convert:\n",
    "        df[col] = df[col].astype('category')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Quit all electric columns from data['Combustion']\n",
    "for column in data['Combustion'].columns:\n",
    "    if column.startswith('electric'):\n",
    "        data['Combustion'] = data['Combustion'].drop(columns=column)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert object columns to category\n",
    "data['Combustion'] = category_convert(data['Combustion'])\n",
    "\n",
    "categorical_columns = get_combustion_categorical_columns(data['Combustion'])\n",
    "\n",
    "categorical_columns = fill_combustion_categorical_columns(categorical_columns)\n",
    "\n",
    "data['Combustion'][categorical_columns.columns] = categorical_columns\n",
    "\n",
    "# Check amount of missing values\n",
    "missing_values = data['Combustion'].isnull().sum()\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "\n",
    "print(missing_values)\n",
    "categorical_columns.head()\n",
    "categorical_columns.columns\n",
    "#categorical_columns['traction']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all na columns \n",
    "data['Combustion'] = drop_columns_full_nan(data['Combustion'])\n",
    "\n",
    "numerical_columns = get_combustion_numerical_columns(data['Combustion'])\n",
    "\n",
    "\n",
    "# fill the missing data in numerical columns\n",
    "numerical_columns = fill_combustion_numerical_columns(numerical_columns)\n",
    "\n",
    "# Check amount of missing values\n",
    "missing_values_num = numerical_columns.isnull().sum()\n",
    "missing_values_num = missing_values_num[missing_values_num > 0]\n",
    "\n",
    "data['Combustion'][numerical_columns.columns] = numerical_columns\n",
    "\n",
    "#correlation_matrix = numerical_columns.corr()\n",
    "#correlation_matrix = correlation_matrix.sort_values(by='price', ascending=False)\n",
    "\n",
    "correlation_matrix\n",
    "print(missing_values_num)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface_hub",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
