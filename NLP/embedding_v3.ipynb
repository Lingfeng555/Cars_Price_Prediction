{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿GPU disponible?: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lingf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../') \n",
    "from utils.loader import Loader\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, Flatten, Input, Concatenate, BatchNormalization, LSTM\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Descargar la lista de stopwords si no está ya descargada\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Cargar las stopwords en español\n",
    "spanish_stopwords = set(stopwords.words('spanish'))\n",
    "\n",
    "\n",
    "print(\"¿GPU disponible?:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lingf\\OneDrive\\Escritorio\\SRC\\Cars_Price_Prediction-1\\NLP\\..\\utils\\loader.py:153: DtypeWarning: Columns (120) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path,\n",
      "c:\\Users\\lingf\\OneDrive\\Escritorio\\SRC\\Cars_Price_Prediction-1\\NLP\\..\\utils\\loader.py:153: DtypeWarning: Columns (120) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path,\n",
      "c:\\Users\\lingf\\OneDrive\\Escritorio\\SRC\\Cars_Price_Prediction-1\\NLP\\..\\utils\\loader.py:165: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"km\"].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "train = Loader.load_NLP()[:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['motor_description', 'transmission_description', 'parking_sensors_description', 'Exterior_Llantas_description', 'Exterior_Molduras_description', 'Exterior_Neumáticos_description', 'Exterior_Puerta_description', 'Exterior_Retrovisor_description', 'Confort_Volante_description', 'seat_description', 'head_supporter_description']\n"
     ]
    }
   ],
   "source": [
    "descriptions = [col for col in train.columns if \"description\" in col]\n",
    "\n",
    "print(descriptions)\n",
    "\n",
    "def custom_concat(row, cols):\n",
    "    # Construir la descripción con lógica condicional basada en el valor de la celda\n",
    "    parts = []\n",
    "    for col_name in cols:  # Cambio para iterar solo sobre las columnas especificadas\n",
    "        if col_name in row.index:  # Verificar que el nombre de la columna esté en el DataFrame\n",
    "            value = row[col_name]\n",
    "            if value == \"no tiene\" or not isinstance(value, str):\n",
    "                parts.append(f\"no tiene {col_name}\")\n",
    "            else:\n",
    "                parts.append(str(value))  # Convertir a string para evitar problemas al unir\n",
    "    # Unir todas las partes con espacios\n",
    "    return ' '.join(parts)\n",
    "\n",
    "# Aplicar la función al DataFrame\n",
    "train['full_description'] = train.apply(custom_concat, axis=1, args=(descriptions,))\n",
    "#train[descriptions].apply(lambda col: col.apply(lambda x: type(x).__name__).value_counts())\n",
    "\n",
    "#descriptions.append(\"idx\")\n",
    "#descriptions.append(\"price\")\n",
    "#descriptions.append(\"km\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>km</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>full_description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10600</td>\n",
       "      <td>99700.0</td>\n",
       "      <td>Gasolina</td>\n",
       "      <td>Motor de 1,8 litros ( 1.798 cc ) , 4 cilindros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12450</td>\n",
       "      <td>91924.0</td>\n",
       "      <td>Gasolina</td>\n",
       "      <td>Motor de 1,4 litros ( 1.362 cc ) , cuatro cili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134900</td>\n",
       "      <td>62000.0</td>\n",
       "      <td>Gasolina</td>\n",
       "      <td>Motor de 3,8 litros ( 3.800 cc ) , seis cilind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27500</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>Eléctrico</td>\n",
       "      <td>no tiene motor_description Transmisión de tipo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27990</td>\n",
       "      <td>13559.0</td>\n",
       "      <td>Híbrido</td>\n",
       "      <td>Motor de 1,5 litros ( 1.498 cc ) , cuatro cili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20029</th>\n",
       "      <td>7500</td>\n",
       "      <td>74000.0</td>\n",
       "      <td>Gasolina</td>\n",
       "      <td>Motor de 1,2 litros ( 1.198 cc ) , tres cilind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20030</th>\n",
       "      <td>21990</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Híbrido</td>\n",
       "      <td>Motor de 1,0 litros ( 998 cc ) , tres cilindro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20031</th>\n",
       "      <td>22990</td>\n",
       "      <td>148000.0</td>\n",
       "      <td>Diésel</td>\n",
       "      <td>Motor de 2,0 litros ( 1.968 cc ) , cuatro cili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20032</th>\n",
       "      <td>18800</td>\n",
       "      <td>119000.0</td>\n",
       "      <td>Diésel</td>\n",
       "      <td>Motor de 2,0 litros ( 1.968 cc ) , cuatro cili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20033</th>\n",
       "      <td>2999</td>\n",
       "      <td>340000.0</td>\n",
       "      <td>Diésel</td>\n",
       "      <td>Motor de 1,9 litros ( 1.896 cc ) , 4 cilindros...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        price        km   fuelType  \\\n",
       "idx                                  \n",
       "0       10600   99700.0   Gasolina   \n",
       "1       12450   91924.0   Gasolina   \n",
       "2      134900   62000.0   Gasolina   \n",
       "3       27500   13500.0  Eléctrico   \n",
       "4       27990   13559.0    Híbrido   \n",
       "...       ...       ...        ...   \n",
       "20029    7500   74000.0   Gasolina   \n",
       "20030   21990      10.0    Híbrido   \n",
       "20031   22990  148000.0     Diésel   \n",
       "20032   18800  119000.0     Diésel   \n",
       "20033    2999  340000.0     Diésel   \n",
       "\n",
       "                                        full_description  \n",
       "idx                                                       \n",
       "0      Motor de 1,8 litros ( 1.798 cc ) , 4 cilindros...  \n",
       "1      Motor de 1,4 litros ( 1.362 cc ) , cuatro cili...  \n",
       "2      Motor de 3,8 litros ( 3.800 cc ) , seis cilind...  \n",
       "3      no tiene motor_description Transmisión de tipo...  \n",
       "4      Motor de 1,5 litros ( 1.498 cc ) , cuatro cili...  \n",
       "...                                                  ...  \n",
       "20029  Motor de 1,2 litros ( 1.198 cc ) , tres cilind...  \n",
       "20030  Motor de 1,0 litros ( 998 cc ) , tres cilindro...  \n",
       "20031  Motor de 2,0 litros ( 1.968 cc ) , cuatro cili...  \n",
       "20032  Motor de 2,0 litros ( 1.968 cc ) , cuatro cili...  \n",
       "20033  Motor de 1,9 litros ( 1.896 cc ) , 4 cilindros...  \n",
       "\n",
       "[20000 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_columns = [\"price\", \"km\", \"fuelType\", \"full_description\"]\n",
    "train = train[filtered_columns]\n",
    "train.dropna(inplace=True)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "verb_size = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Convertir a minúsculas y eliminar caracteres especiales (pero mantener los números)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s\\d]', '', text)  # Eliminar signos de puntuación, pero mantener números\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Filtrar tokens, eliminando las stopwords\n",
    "    filtered_tokens = [token for token in tokens if token not in spanish_stopwords]\n",
    "    \n",
    "    return filtered_tokens\n",
    "\n",
    "train['tokens'] = train['full_description'].apply(preprocess_text)\n",
    "model_w2v = Word2Vec(sentences=train['tokens'], vector_size=verb_size, window=1, min_count=3, workers=8)\n",
    "word_vectors = model_w2v.wv\n",
    "\n",
    "def get_average_embedding(tokens, model):\n",
    "    embeddings = [model[word] for word in tokens if word in model]\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size) \n",
    "train['embedding'] = train['tokens'].apply(lambda x: get_average_embedding(x, word_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_km = train['km'].to_numpy().reshape(-1, 1)\n",
    "scaler_km = StandardScaler()\n",
    "x_km_scaled = scaler_km.fit_transform(x_km)\n",
    "\n",
    "y = train['price'].to_numpy()\n",
    "scaler_y = StandardScaler()\n",
    "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (assuming df is your DataFrame containing the required columns)\n",
    "texts = train['full_description'].values  # descriptions\n",
    "embeddings = train['embedding'].values  # embeddings\n",
    "\n",
    "# Tokenization and sequence padding\n",
    "tokenizer = Tokenizer(num_words=verb_size)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "data = pad_sequences(sequences,  maxlen=verb_size, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "train_data, test_data, train_embeddings, test_embeddings, train_prices, test_prices, train_km, test_km = train_test_split(\n",
    "    data, embeddings, train['price'], train['km'], test_size=0.2, random_state=42, stratify=train['fuelType'])\n",
    "\n",
    "# Normalize embeddings\n",
    "train_embeddings = tf.keras.utils.normalize(train_embeddings)\n",
    "test_embeddings = tf.keras.utils.normalize(test_embeddings)\n",
    "train_embeddings = np.transpose(train_embeddings)\n",
    "test_embeddings = np.transpose(test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_prices.shape)\n",
    "print(train['km'].shape)\n",
    "print(train_km.shape)\n",
    "print(test_km.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_embedding(embed):\n",
    "    standard_length = 200\n",
    "    flat_embed = np.concatenate([np.array(e).flatten() for e in embed])  # Flatten\n",
    "    # Pad with zeros or truncate to the standard length\n",
    "    if len(flat_embed) > standard_length:\n",
    "        return flat_embed[:standard_length]\n",
    "    elif len(flat_embed) < standard_length:\n",
    "        return np.pad(flat_embed, (0, standard_length - len(flat_embed)), mode='constant')\n",
    "    return flat_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings = np.array([process_embedding(e) for e in train_embeddings], dtype=np.float32)\n",
    "train_embeddings = tf.convert_to_tensor(train_embeddings, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings = np.array([process_embedding(e) for e in test_embeddings], dtype=np.float32)\n",
    "test_embeddings = tf.convert_to_tensor(test_embeddings, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.convert_to_tensor(train_data, dtype=tf.int32)\n",
    "test_data = tf.convert_to_tensor(test_data, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prices = tf.convert_to_tensor(train_prices, dtype=tf.float32)\n",
    "test_prices = tf.convert_to_tensor(test_prices, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_km = tf.convert_to_tensor(train_km, dtype=tf.float32)\n",
    "train_km = tf.convert_to_tensor(train_km, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_km.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text input branch\n",
    "text_input = Input(shape=(200,), dtype='int32')\n",
    "text_embed_layer = Embedding(input_dim=verb_size, output_dim=verb_size, input_length=train_data.shape[1])\n",
    "text_embed = text_embed_layer(text_input)\n",
    "lstm_out = LSTM(128)(text_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding input branch\n",
    "embed_input = Input(shape=(train_embeddings.shape[1],), dtype = 'int32')\n",
    "dense_embed = Dense(128, activation='relu')(embed_input)\n",
    "\n",
    "# KM branch\n",
    "input_km = Input(shape=(1,), name='km_input')\n",
    "km_processed = Dense(32, activation='relu')(input_km)\n",
    "\n",
    "# Concatenate both branches\n",
    "concat = Concatenate()([lstm_out, dense_embed, km_processed])\n",
    "hidden = Dense(256, activation='relu')(concat)\n",
    "output = Dense(1, activation='linear')(hidden)  # Output layer for price prediction\n",
    "\n",
    "model = Model(inputs=[text_input, embed_input, input_km], outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.shape)      # Should be (number of samples, sequence length)\n",
    "print(train_embeddings.shape)\n",
    "print(train_km.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"COMIENZA EL ENTRENAMIENTO...\")\n",
    "history = model.fit([train_data, train_embeddings, train_km], train_prices,\n",
    "          validation_data=([test_data, test_embeddings, test_km], test_prices),\n",
    "          epochs=1, batch_size=64)\n",
    "print(\"TERMINA EL ENTRENAMIENTO...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"# Epoca\")\n",
    "plt.ylabel(\"Loss magnitude\")\n",
    "plt.plot(history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_mse = model.evaluate([test_data, test_embeddings, test_km], test_prices)\n",
    "print(f'Test MAE: {test_mse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_prices = model.predict([test_data, test_embeddings, test_km])\n",
    "\n",
    "# Assuming test_prices is a 1D array, we can convert it to a DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual Price': test_prices,\n",
    "    'Predicted Price': predicted_prices.flatten(),  # Flatten in case it's a 2D array\n",
    "    'km' : test_km\n",
    "})\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(results_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
