{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../') \n",
    "from utils.loader import Loader\n",
    "from utils.data_processor import Data_processor\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.decomposition import PCA,TruncatedSVD\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.feature_selection import chi2\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import prince\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nitram/asignaturas/machine learning/Cars_Price_Prediction/Trees/../utils/loader.py:153: DtypeWarning: Columns (120) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path,\n",
      "/home/nitram/asignaturas/machine learning/Cars_Price_Prediction/Trees/../utils/loader.py:153: DtypeWarning: Columns (120) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path,\n",
      "/home/nitram/asignaturas/machine learning/Cars_Price_Prediction/Trees/../utils/loader.py:165: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[\"km\"].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data = Loader.load_by_fueltype(\"Combustion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns_full_nan(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    #Remove the column that only contain NAs\n",
    "    cols_to_drop = data.columns[data.isna().all()]\n",
    "    data = data.drop(cols_to_drop, axis=1)\n",
    "    return data\n",
    "\n",
    "def get_combustion_numerical_columns (data: pd.DataFrame) -> pd.DataFrame:\n",
    "    numerical_columns = data.select_dtypes(include=['number'])\n",
    "\n",
    "    #if all the values of the numerical columns is 0, we rem['Combustion']ove the column\n",
    "    cols_to_drop = numerical_columns.columns[(numerical_columns == 0).all()]\n",
    "    numerical_columns = numerical_columns.drop(cols_to_drop, axis=1)\n",
    "    return numerical_columns\n",
    "\n",
    "def fill_combustion_numerical_columns(numerical_columns: pd.DataFrame) -> pd.DataFrame:\n",
    "    cols_mode = ['displacement_liters','doors','seatingCapacity','number_of_cylinders','cubicCapacity',\"dimensions.length\",\"dimensions.height\",\"Llantas_Diametro_cm\",\"number_of_cylinders\",\"bore_diameter\",\"stroke_length\"]\n",
    "    #fill the elemental columns that has a minor amount of missing data with the mode\n",
    "    for col in cols_mode:\n",
    "        numerical_columns = Data_processor.fill_na_with_mode(numerical_columns, col)\n",
    "\n",
    "    #fill the missing data witch regression, the parameters were based on the relation matrix \n",
    "    numerical_columns = Data_processor.impute_with_linear_regression(data=numerical_columns, x_columns=[\"dimensions.length\", \"dimensions.height\"], y_column=\"dimensions.width\")\n",
    "    numerical_columns = Data_processor.impute_with_linear_regression(data=numerical_columns, x_columns=[\"dimensions.length\", \"dimensions.height\", \"dimensions.width\"], y_column=\"trunkCapacityInLiters\")\n",
    "    numerical_columns = Data_processor.impute_with_linear_regression(data=numerical_columns, x_columns=[\"power_cv\", \"power_kw\"], y_column=\"maxSpeed\")\n",
    "    numerical_columns = Data_processor.impute_with_linear_regression(data=numerical_columns, x_columns=[\"power_cv\", \"power_kw\", \"maxSpeed\"], y_column=\"acceleration\")\n",
    "    numerical_columns = Data_processor.impute_with_linear_regression(data=numerical_columns, x_columns=[\"power_cv\", \"power_kw\", \"maxSpeed\"], y_column=\"acceleration\")\n",
    "    numerical_columns = Data_processor.impute_with_linear_regression(data=numerical_columns, x_columns=[\"Llantas_Diametro_cm\", \"power_kw\"], y_column=\"max_torque_nm\")\n",
    "    numerical_columns = Data_processor.impute_with_linear_regression(data=numerical_columns, x_columns=[\"Llantas_Diametro_cm\", \"power_kw\"], y_column=\"rpm_max_torque\")\n",
    "    numerical_columns = Data_processor.impute_with_linear_regression(data=numerical_columns, x_columns=[\"Llantas_Diametro_cm\", \"power_kw\"], y_column=\"rpm_max_power\")\n",
    "    numerical_columns.dropna(axis=1, inplace=True)\n",
    "    return numerical_columns\n",
    "\n",
    "def get_combustion_categorical_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Select and print only the categorical columns\n",
    "    ret = df.select_dtypes(include=['category'])\n",
    "    \n",
    "    # Temporarily convert the column to strings to perform the replacement\n",
    "    ret['traction'] = ret['traction'].astype(str).replace({\"trasera\": \"trasero\", \"delantera\": \"delantero\"})\n",
    "    # Convert back to a categorical type\n",
    "    ret['traction'] = ret['traction'].astype('category')\n",
    "\n",
    "    \n",
    "    # Remove redundant columns if this function is defined\n",
    "    ret = Data_processor.remove_redundand_columns(ret)\n",
    "    return ret\n",
    "\n",
    "\n",
    "def fill_combustion_categorical_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    mode_cols = ['brakes','version','jato_classification']\n",
    "    for col in mode_cols:\n",
    "        df = Data_processor.fill_na_with_mode(df, col)\n",
    "    df = Data_processor.impute_categorical_mode(df=df, X=[\"brand\", \"model\", \"traction\",\"brakes\"], Y=\"front_suspension\")\n",
    "    df = Data_processor.impute_categorical_mode(df=df, X=[\"brand\", \"model\", \"traction\",\"brakes\"], Y=\"rear_suspension\")\n",
    "    df = Data_processor.impute_categorical_mode(df=df, X=[\"brand\", \"model\"] , Y=\"environmentalLabel\")\n",
    "    return df\n",
    "\n",
    "def category_convert(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    cols_to_convert = df.select_dtypes(include=['object']).columns\n",
    "    for col in cols_to_convert:\n",
    "        df[col] = df[col].astype('category')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quit all electric columns from data['Combustion']\n",
    "for column in data.columns:\n",
    "    if column.startswith('electric'):\n",
    "        data = data.drop(columns=column)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'co2Emissions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m data \u001b[38;5;241m=\u001b[39m category_convert(data)\n\u001b[1;32m      4\u001b[0m categorical_columns \u001b[38;5;241m=\u001b[39m get_combustion_categorical_columns(data)\n\u001b[0;32m----> 6\u001b[0m categorical_columns \u001b[38;5;241m=\u001b[39m \u001b[43mfill_combustion_categorical_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcategorical_columns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Check amount of missing values\u001b[39;00m\n\u001b[1;32m      9\u001b[0m missing_values \u001b[38;5;241m=\u001b[39m categorical_columns\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum()\n",
      "Cell \u001b[0;32mIn[11], line 54\u001b[0m, in \u001b[0;36mfill_combustion_categorical_columns\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     52\u001b[0m df \u001b[38;5;241m=\u001b[39m Data_processor\u001b[38;5;241m.\u001b[39mimpute_categorical_mode(df\u001b[38;5;241m=\u001b[39mdf, X\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrand\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraction\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrakes\u001b[39m\u001b[38;5;124m\"\u001b[39m], Y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfront_suspension\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     53\u001b[0m df \u001b[38;5;241m=\u001b[39m Data_processor\u001b[38;5;241m.\u001b[39mimpute_categorical_mode(df\u001b[38;5;241m=\u001b[39mdf, X\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrand\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraction\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrakes\u001b[39m\u001b[38;5;124m\"\u001b[39m], Y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrear_suspension\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 54\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mData_processor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimpute_categorical_mode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbrand\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mco2Emissions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mco2EmissionsGramsPerKm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43menvironmentalLabel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/asignaturas/machine learning/Cars_Price_Prediction/Trees/../utils/data_processor.py:76\u001b[0m, in \u001b[0;36mData_processor.impute_categorical_mode\u001b[0;34m(df, X, Y)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimpute_categorical_mode\u001b[39m(df, X, Y):\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X)):\n\u001b[0;32m---> 76\u001b[0m         df \u001b[38;5;241m=\u001b[39m \u001b[43mData_processor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__impute_categorical_mode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m         X\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;28mlen\u001b[39m(X)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     78\u001b[0m     df[Y] \u001b[38;5;241m=\u001b[39m df[Y]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munkown\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m#If is a unique car\u001b[39;00m\n",
      "File \u001b[0;32m~/asignaturas/machine learning/Cars_Price_Prediction/Trees/../utils/data_processor.py:59\u001b[0m, in \u001b[0;36mData_processor.__impute_categorical_mode\u001b[0;34m(df, X, Y)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__impute_categorical_mode\u001b[39m(df, X, Y):\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;66;03m# Agrupar por las columnas X y calcular el valor más común (moda) en la columna Y para cada grupo\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m     modes \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[Y]\u001b[38;5;241m.\u001b[39magg(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39mmode()[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39mempty \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, )\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m     60\u001b[0m     modes\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{Y: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMode\u001b[39m\u001b[38;5;124m'\u001b[39m}, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# Unir el DataFrame original con los modos encontrados para facilitar la imputación\u001b[39;00m\n",
      "File \u001b[0;32m~/.venvs/huggingface_hub/lib/python3.12/site-packages/pandas/core/frame.py:9183\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   9180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   9181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 9183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   9184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9186\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9189\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9193\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venvs/huggingface_hub/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1329\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1329\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1334\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1337\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m   1340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[0;32m~/.venvs/huggingface_hub/lib/python3.12/site-packages/pandas/core/groupby/grouper.py:1043\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m   1041\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1043\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'co2Emissions'"
     ]
    }
   ],
   "source": [
    "# convert object columns to category\n",
    "data = category_convert(data)\n",
    "\n",
    "categorical_columns = get_combustion_categorical_columns(data)\n",
    "\n",
    "categorical_columns = fill_combustion_categorical_columns(categorical_columns)\n",
    "\n",
    "# Check amount of missing values\n",
    "missing_values = categorical_columns.isnull().sum()\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "\n",
    "print(missing_values)\n",
    "categorical_columns.head()\n",
    "categorical_columns.columns\n",
    "#categorical_columns['traction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression mape ['dimensions.length', 'dimensions.height'] -> dimensions.width: 1.6154091221985638%\n",
      "Regression mape ['dimensions.length', 'dimensions.height', 'dimensions.width'] -> trunkCapacityInLiters: 17.70914536272188%\n",
      "Regression mape ['power_cv', 'power_kw'] -> maxSpeed: 6.410215656255149%\n",
      "Regression mape ['power_cv', 'power_kw', 'maxSpeed'] -> acceleration: 7.903819131160306%\n",
      "Regression mape ['power_cv', 'power_kw', 'maxSpeed'] -> acceleration: 6.82454077343871%\n",
      "Regression mape ['Llantas_Diametro_cm', 'power_kw'] -> max_torque_nm: 2.5518090259601084e+16%\n",
      "Regression mape ['Llantas_Diametro_cm', 'power_kw'] -> rpm_max_torque: 67.97560330483189%\n",
      "Regression mape ['Llantas_Diametro_cm', 'power_kw'] -> rpm_max_power: 20.028480167086318%\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Drop all na columns \n",
    "data = drop_columns_full_nan(data)\n",
    "\n",
    "numerical_columns = get_combustion_numerical_columns(data)\n",
    "\n",
    "\n",
    "# fill the missing data in numerical columns\n",
    "numerical_columns = fill_combustion_numerical_columns(numerical_columns)\n",
    "\n",
    "# Check amount of missing values\n",
    "missing_values_num = numerical_columns.isnull().sum()\n",
    "missing_values_num = missing_values_num[missing_values_num > 0]\n",
    "\n",
    "data[numerical_columns.columns] = numerical_columns\n",
    "\n",
    "#correlation_matrix = numerical_columns.corr()\n",
    "#correlation_matrix = correlation_matrix.sort_values(by='price', ascending=False)\n",
    "print(missing_values_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precios_combustion = data[\"price\"]\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot(precios_combustion, notch=True, vert=True, patch_artist=True, showmeans=True)\n",
    "plt.title('Boxplot de Precios')\n",
    "plt.ylabel('Precio')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface_hub",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
