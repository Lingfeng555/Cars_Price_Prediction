{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and load the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../') \n",
    "from utils.loader import Loader\n",
    "from utils.data_processor import Data_processor\n",
    "from utils.evaluator import Evaluator\n",
    "from utils.master_generator import MasterGenerator\n",
    "from utils.cluster_generator import ClusterGenerator\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, log_loss\n",
    "from sklearn.metrics import make_scorer\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.feature_selection import chi2\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#from tensorflow.keras.models import Sequential\n",
    "#from tensorflow.keras.layers import Dense\n",
    "import prince\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Loader.load_by_fueltype(\"Eléctrico\")\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"price_categ\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe some columns\n",
    "A more detailed version of the dataset can be found in the DataDescription.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.select_dtypes(include=['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precios_electricos = data[\"price\"]\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot(precios_electricos, notch=True, vert=True, patch_artist=True, showmeans=True)\n",
    "plt.title('Boxplot de Precios')\n",
    "plt.ylabel('Precio')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The related outliers were checked manually throught the data source, and we could confirmed that they are not outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = data['price'].quantile(0.25)\n",
    "Q2 = data['price'].quantile(0.5)  # Esta es la mediana\n",
    "Q3 = data['price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "upper_whisker = (Q3 + 1.5 * IQR)\n",
    "print(upper_whisker)\n",
    "\n",
    "data[data[\"fuelType\"] == \"Eléctrico\"][data[\"price\"]>upper_whisker][[\"price\", \"brand\"]].sort_values(by='price', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Electric cars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical variables selection Eléctrico\n",
    "Here we will perform PCA and use correlation matrix to select the most correlated numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_electric_numerical_columns(numerical_columns: pd.DataFrame) -> pd.DataFrame:\n",
    "    #fill the elemental columns that has a minor amount of missing data with the mode\n",
    "    numerical_columns = Data_processor.fill_na_with_mode(numerical_columns, \"dimensions.length\")\n",
    "    numerical_columns = Data_processor.fill_na_with_mode(numerical_columns, \"dimensions.height\")\n",
    "    numerical_columns = Data_processor.fill_na_with_mode(numerical_columns, \"electricFeatures.maximumBatteryKWH_kWh\")\n",
    "    numerical_columns = Data_processor.fill_na_with_mode(numerical_columns, \"electricFeatures.onboardCharger_kW\")\n",
    "    numerical_columns = Data_processor.fill_na_with_mode(numerical_columns, \"electricFeatures.range_KM\")\n",
    "\n",
    "    #fill the missing data witch regression, the parameters were based on the relation matrix \n",
    "    numerical_columns = Data_processor.impute_with_linear_regression(data=numerical_columns, x_columns=[\"dimensions.length\", \"dimensions.height\"], y_column=\"dimensions.width\")\n",
    "    numerical_columns = Data_processor.impute_with_linear_regression(data=numerical_columns, x_columns=[\"dimensions.length\", \"dimensions.height\", \"dimensions.width\"], y_column=\"trunkCapacityInLiters\")\n",
    "    numerical_columns = Data_processor.impute_with_linear_regression(data=numerical_columns, x_columns=[\"power_cv\", \"power_kw\"], y_column=\"maxSpeed\")\n",
    "    numerical_columns = Data_processor.impute_with_linear_regression(data=numerical_columns, x_columns=[\"power_cv\", \"power_kw\", \"maxSpeed\"], y_column=\"acceleration\")\n",
    "    numerical_columns = Data_processor.impute_with_linear_regression(data=numerical_columns, x_columns=[\"power_cv\", \"power_kw\", \"maxSpeed\"], y_column=\"acceleration\")\n",
    "    numerical_columns = Data_processor.impute_with_linear_regression(data=numerical_columns, x_columns=[\"Llantas_Diametro_cm\", \"power_kw\"], y_column=\"max_torque_nm\")\n",
    "    numerical_columns = Data_processor.impute_with_linear_regression(data=numerical_columns, x_columns=[\"electricFeatures.maximumBatteryKWH_kWh\", \"power_kw\", \"dimensions.length\", \"dimensions.height\", \"dimensions.width\"], y_column=\"electricFeatures.combinedConsumption_kWh/\")\n",
    "    numerical_columns = Data_processor.impute_with_linear_regression(data=numerical_columns, x_columns=[\"electricFeatures.maximumBatteryKWH_kWh\", \"electricFeatures.combinedConsumption_kWh/\", \"power_kw\"], y_column=\"electricFeatures.range_KM\")\n",
    "    numerical_columns.dropna(axis=1, inplace=True)\n",
    "    return numerical_columns\n",
    "\n",
    "def get_electric_numerical_columns (data: pd.DataFrame) -> pd.DataFrame:\n",
    "    numerical_columns = data.select_dtypes(include=['number'])\n",
    "    numerical_columns.drop(columns=[ \"car_id\", \"electricFeatures.maxPower_CV\"], inplace=True) # electricFeatures.maxPower_CV is = power_cv (Duplicated colums)\n",
    "\n",
    "    #if all the values of the numerical columns is 0, we remove the column\n",
    "    cols_to_drop = numerical_columns.columns[(numerical_columns == 0).all()]\n",
    "    numerical_columns = numerical_columns.drop(cols_to_drop, axis=1)\n",
    "\n",
    "    #Remove the column with all NAs\n",
    "    max_nans = 6586\n",
    "    thresh = numerical_columns.shape[0] - max_nans\n",
    "\n",
    "    numerical_columns.dropna(axis=1, thresh=thresh+1, inplace=True)\n",
    "    return fill_electric_numerical_columns(numerical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = get_electric_numerical_columns(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = numerical_columns.corr()[\"price\"]\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df_scaled  = scaler.fit_transform(numerical_columns)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(df_scaled)\n",
    "df_pca = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biplot(score, coeff, labels=None):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    origin = [0, 0]  # Origen de las flechas\n",
    "\n",
    "    # Dibujar las flechas\n",
    "    for i in range(len(coeff)):\n",
    "        plt.arrow(origin[0], origin[1], coeff[i,0], coeff[i,1], color='r', alpha=0.5, head_width=0.05, head_length=0.1)\n",
    "        if labels is not None:\n",
    "            plt.text(coeff[i,0]*1.15, coeff[i,1]*1.15, labels[i], color='blue', ha='center', va='center')\n",
    "\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.title(\"Biplot\")\n",
    "    plt.grid(True)\n",
    "    plt.axhline(0, color='black',linewidth=0.5)\n",
    "    plt.axvline(0, color='black',linewidth=0.5)\n",
    "    plt.xlim(min(coeff[:,0])*1.2, max(coeff[:,0])*1.2)\n",
    "    plt.ylim(min(coeff[:,1])*1.2, max(coeff[:,1])*1.2)\n",
    "    plt.show()\n",
    "\n",
    "# Llamada a la función biplot\n",
    "biplot(principal_components, np.transpose(pca.components_[0:2, :]), labels=numerical_columns.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns.drop(columns=[\"Numero_Testigos\", \"dimensions.height\", \"doors\", \"electricFeatures.onboardCharger_kW\", \"seatingCapacity\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test CART regression trees with only numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = numerical_columns.drop(columns=\"price\")\n",
    "y = numerical_columns[\"price\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "tree_model = DecisionTreeRegressor(random_state=42)\n",
    "tree_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# Realizar predicciones sobre el conjunto de prueba\n",
    "y_pred = tree_model.predict(X_test)\n",
    "\n",
    "Evaluator.eval_regression(y_pred, y_test, plot= True, bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Electrico categorical variables\n",
    "Here we will perform CA and Chi2 test to select the best categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_electric_categorical_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ret = df.select_dtypes(include=['category'])\n",
    "    ret = ret.drop(columns=[\"environmentalLabel\"]) #All of the cars of this dataframes are electrical which implies 0 emission\n",
    "    ret = Data_processor.remove_redundand_columns(ret)\n",
    "    ret = Data_processor.impute_categorical_mode(df=ret, X=[\"brand\", \"model\"], Y=\"version\")\n",
    "    ret = Data_processor.impute_categorical_mode(df=ret, X=[\"brand\", \"model\"], Y=\"jato_classification\")\n",
    "    ret = Data_processor.impute_categorical_mode(df=ret, X=[\"brand\", \"model\", \"traction\"], Y=\"brakes\")\n",
    "    ret = Data_processor.impute_categorical_mode(df=ret, X=[\"brand\", \"model\", \"traction\",\"brakes\"], Y=\"front_suspension\")\n",
    "    ret = Data_processor.impute_categorical_mode(df=ret, X=[\"brand\", \"model\", \"traction\",\"brakes\"], Y=\"rear_suspension\")\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = get_electric_categorical_columns(data)\n",
    "print(\"\\nCategorical Columns Index:\")\n",
    "print(categorical_columns.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_processor.chi_square_test(categorical_columns=categorical_columns, column_y=\"price_categ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_processor.CA(categorical_columns=categorical_columns, col_x=\"province\", col_y=\"price_categ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns[\"price_categ\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = Data_processor.chi_square_filter(categorical_columns, \"price_categ\", p_value_filter=0)\n",
    "categorical_columns.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test CART tree classifier with only categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.get_dummies(categorical_columns.drop('price_categ', axis=1))\n",
    "\n",
    "# Your target variable\n",
    "target = categorical_columns['price_categ'].apply(Loader.encode_price_categ)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_df, target, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the Decision Tree Classifier\n",
    "cart_model = DecisionTreeClassifier(random_state=42)\n",
    "cart_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the test set results\n",
    "y_pred = cart_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\"Real_Categorie\": y_test, \"Prediction\": y_pred})\n",
    "result[\"diff\"] = np.abs(result[\"Real_Categorie\"].astype(int) - result[\"Prediction\"])\n",
    "result[\"Real_Categorie\"] = result[\"Real_Categorie\"].apply(Loader.decode_price_categ)\n",
    "result[\"Prediction\"] = result[\"Prediction\"].apply(Loader.decode_price_categ)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la precisión\n",
    "Evaluator.eval_classification(y_pred=result[\"Prediction\"].to_numpy(), y_true=result[\"Real_Categorie\"].to_numpy(), binary_classification=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify that the prediction is not very accurate but we need to know how big is the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluator.eval_ordinal_classification (result[\"diff\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even having errors, we can verify that the errors are not that big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "# Dibujar el árbol de decisión\n",
    "plot_tree(tree_model, \n",
    "          filled=True, \n",
    "          rounded=True, \n",
    "          class_names=X_train.columns, \n",
    "          feature_names=X.columns, \n",
    "          max_depth=3)  # Puedes ajustar la profundidad para una mejor visualización o quitar este parámetro para mostrar todo el árbol\n",
    "plt.title('Visualización del Árbol de Decisión')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agorithms evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electric_cars = pd.merge(numerical_columns, categorical_columns, left_index=True, right_index=True, how='inner')\n",
    "numerical_column_names = list(numerical_columns.columns)\n",
    "categorical_column_names = list(categorical_columns.columns)\n",
    "print(electric_cars.shape)\n",
    "target = electric_cars[[\"price\", \"price_categ\"]]\n",
    "electric_cars.drop(columns=[\"price\", \"price_categ\"], inplace=True)\n",
    "\n",
    "\n",
    "numerical_column_names.remove(\"price\")\n",
    "categorical_column_names.remove(\"price_categ\")\n",
    "\n",
    "encoders_and_scalers = {}\n",
    "for column in numerical_column_names:\n",
    "    scaler = StandardScaler()\n",
    "    electric_cars[[column]] = scaler.fit_transform(electric_cars[[column]])\n",
    "    encoders_and_scalers[column] = scaler \n",
    "\n",
    "electric_cars_encoded = pd.get_dummies(electric_cars, columns=categorical_column_names)\n",
    "print(electric_cars_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "# Merge numerical and categorical columns\n",
    "combustion_cars = pd.merge(numerical_columns, categorical_columns, left_index=True, right_index=True, how=\"inner\")\n",
    "numerical_column_names = list(numerical_columns.columns)\n",
    "categorical_column_names = list(categorical_columns.columns)\n",
    "\n",
    "# Separate target variables\n",
    "target = combustion_cars[[\"price\", \"price_categ\"]]\n",
    "target[\"price_categ\"] = target[\"price_categ\"].apply(Loader.encode_price_categ)\n",
    "combustion_cars.drop(columns=[\"price\", \"price_categ\"], inplace=True)\n",
    "\n",
    "# Update feature lists by removing targets\n",
    "numerical_column_names.remove(\"price\")\n",
    "categorical_column_names.remove(\"price_categ\")\n",
    "\n",
    "# Initialize dictionary to store encoders/scalers\n",
    "encoders_and_scalers = {}\n",
    "\n",
    "# Scale and apply PCA to numerical columns\n",
    "numerical_data = combustion_cars[numerical_column_names]\n",
    "scaler = StandardScaler()\n",
    "numerical_data_scaled = scaler.fit_transform(numerical_data)\n",
    "\n",
    "# Apply IncrementalPCA to numerical data\n",
    "incremental_pca_numerical = PCA(n_components=0.95)\n",
    "numerical_data_pca = incremental_pca_numerical.fit_transform(numerical_data_scaled)\n",
    "\n",
    "# Store the scaler and PCA for numerical columns\n",
    "encoders_and_scalers[\"numerical_scaler\"] = scaler\n",
    "encoders_and_scalers[\"numerical_pca\"] = incremental_pca_numerical\n",
    "\n",
    "# Encode categorical columns (sparse matrix)\n",
    "encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True)\n",
    "categorical_data_encoded = encoder.fit_transform(combustion_cars[categorical_column_names])\n",
    "\n",
    "# Instead of PCA on categorical data, use TruncatedSVD for sparse matrix\n",
    "svd_categorical = TruncatedSVD(n_components=30)\n",
    "categorical_data_svd = svd_categorical.fit_transform(categorical_data_encoded)\n",
    "\n",
    "# Store the encoder and SVD for categorical columns\n",
    "encoders_and_scalers[\"categorical_encoder\"] = encoder\n",
    "encoders_and_scalers[\"categorical_svd\"] = svd_categorical\n",
    "\n",
    "# Combine the PCA-transformed numerical and SVD-transformed categorical data\n",
    "combustion_cars_encoded = pd.DataFrame(\n",
    "    data=np.hstack([numerical_data_pca, categorical_data_svd]),\n",
    "    index=combustion_cars.index\n",
    ")\n",
    "\n",
    "print(\"Shape after dimensionality reduction:\")\n",
    "print(combustion_cars_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(electric_cars_encoded, target['price_categ'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "def eval_classification(y_test, y_pred):\n",
    "    result = pd.DataFrame({\"Real\": y_test, \"Prediction\": y_pred})\n",
    "    result[\"diff\"] = result[\"Real\"].apply(Loader.encode_price_categ).to_numpy() - result[\"Prediction\"].apply(Loader.encode_price_categ).to_numpy()\n",
    "    Evaluator.eval_ordinal_classification(diff=result[\"diff\"])\n",
    "\n",
    "def classify(X_train, X_test, y_train, y_test , classifier, classifier_name = None) -> None:\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting the test set results\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    eval_classification(y_test, y_pred)\n",
    "\n",
    "    if classifier_name != None:\n",
    "        Evaluator.eval_classification(y_pred = y_pred, y_true=y_test, binary_classification=False, classifier_name=classifier_name)\n",
    "    else:  Evaluator.eval_classification(y_pred = y_pred, y_true=y_test, binary_classification=False)\n",
    "    cv_scores = cross_val_score(classifier, X_test, y_test, cv=5, scoring='accuracy')\n",
    "    Evaluator.plot_bar_chart_key_value(keys= [f\"Fold {i+1}\" for i in range(len(cv_scores))], values=cv_scores, title=f\"Accuracy 5 folder Cross-validation\", xlabel=\"fold\", ylabel=\"accuracy\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(X_train, X_test, y_train, y_test, DecisionTreeClassifier(random_state=42), classifier_name=\"CART\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest\n",
    "Random forest can get a better result at a higher computational time cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(X_train, X_test, y_train, y_test, RandomForestClassifier(random_state=42), classifier_name=\"RandomForestClassifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM\n",
    "Much higher computational cost, more distributed error, but in overall worse result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(X_train, X_test, y_train, y_test, SVC(random_state=42), classifier_name=\"SVC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(X_train, X_test, y_train, y_test, GaussianNB(), classifier_name=\"Naive bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_encoded = encoder.fit_transform(target[['price_categ']])\n",
    "\n",
    "# Step 2: Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    electric_cars_encoded, y_encoded, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Step 3: Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Step 4: Define the ANN model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(64, activation='tanh'))\n",
    "model.add(Dense(32, activation='tanh'))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))  # Softmax for multi-class classification\n",
    "\n",
    "# Step 5: Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 6: Train the model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluator.eval_classification(y_pred=y_pred_classes, y_true=y_test_classes, binary_classification=False, classifier_name=\"ANN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(electric_cars_encoded, target['price'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression(X_train, X_test, y_train, y_test , regressor, regressor_name = None) -> None:\n",
    "    regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting the test set results\n",
    "    y_pred = regressor.predict(X_test)\n",
    "    if regressor_name != None:\n",
    "        Evaluator.eval_regression(y_pred = y_pred, y_true=y_test, plot=False, n_features=len(electric_cars_encoded.columns), regressor_name=regressor_name)\n",
    "    else :Evaluator.eval_regression(y_pred = y_pred, y_true=y_test, plot=False)\n",
    "    mape_scorer = make_scorer(mean_absolute_percentage_error, greater_is_better=False)\n",
    "    cv_scores = -cross_val_score(regressor, X_test, y_test, cv=5, scoring=mape_scorer)\n",
    "    Evaluator.plot_bar_chart_key_value(keys= [f\"Fold {i+1}\" for i in range(len(cv_scores))], values=cv_scores, title=f\"Accuracy 5 folder Cross-validation\", xlabel=\"fold\", ylabel=\"MAPE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression(X_train, X_test, y_train, y_test , DecisionTreeRegressor(random_state=42), regressor_name=\"CART\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression(X_train, X_test, y_train, y_test , RandomForestRegressor(random_state=42), regressor_name=\"RandomForest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression(X_train, X_test, y_train, y_test , SVR(kernel='sigmoid'), regressor_name=\"SVR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariable regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regressor = LinearRegression()\n",
    "linear_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the test set results\n",
    "y_pred = linear_regressor.predict(X_test)\n",
    "\n",
    "# Optionally, display the coefficients of the model\n",
    "print(\"Coefficients:\", linear_regressor.coef_)\n",
    "print(\"Intercept:\", linear_regressor.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\"Real\": y_test, \"Prediction\": y_pred})\n",
    "result[\"diff\"] = result[\"Real\"].to_numpy() - result[\"Prediction\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluator.eval_regression(y_pred = y_pred, y_true=y_test, plot=False, n_features=len(electric_cars_encoded.columns), regressor_name=\"Lineal Regression\")\n",
    "mape_scorer = make_scorer(mean_absolute_percentage_error, greater_is_better=False)\n",
    "cv_scores = -cross_val_score(linear_regressor, X_test, y_test, cv=5, scoring=mape_scorer)\n",
    "Evaluator.plot_bar_chart_key_value(keys= [f\"Fold {i+1}\" for i in range(len(cv_scores))], values=cv_scores, title=f\"Accuracy 5 folder Cross-validation\", xlabel=\"fold\", ylabel=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='linear'))\n",
    "model.add(Dense(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, mae = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Mean Absolute Error on test set: {mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss curve\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Model Loss Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluator.eval_regression(y_pred=y_pred, y_true=y_test, plot=False, n_features=len(electric_cars_encoded.columns), regressor_name=\"ANN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluator.save(\"electric_plug\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameter tuning and Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = MasterGenerator(X=electric_cars_encoded, y_categ=target[\"price_categ\"], y_numeric=target[\"price_categ\"], n_tries=128, CUML=True, name=\"HP_electric_and_plugin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master.generate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
