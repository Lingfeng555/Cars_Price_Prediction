{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gas CART\n",
    "\n",
    "## Import and load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../') \n",
    "from utils.loader import Loader\n",
    "from utils.data_processor import Data_processor\n",
    "from utils.cluster_generator import ClusterGenerator\n",
    "from utils.master_generator import MasterGenerator\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.decomposition import PCA,TruncatedSVD\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.feature_selection import chi2\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from utils.evaluator import Evaluator\n",
    "import prince\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC, SVR\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load GAS type cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Loader.load_by_fueltype(\"Gas\")\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"price_categ\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['price_categ'] = data['price_categ'].replace({ # Combinar clases similares\n",
    "    'Luxury': 'Alto',\n",
    "    'Premiun': 'Alto',\n",
    "    'High end': 'Alto',\n",
    "    'Middle high range': 'Alto',\n",
    "})\n",
    "\n",
    "data = data[data['price_categ'] != 'Very low end'] # Eliminar la clase 'Very low end'\n",
    "data['price_categ'] = data['price_categ'].str.strip()\n",
    "\n",
    "# Revisa la nueva distribuciÃ³n\n",
    "data['price_categ'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar y transformar la columna price_categ\n",
    "data['price_categ'] = data[\"price_categ\"].apply(Loader.encode_price_categ).to_numpy()\n",
    "data['price_categ'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see the data is hightly unbalance and needs treatment before reating the tree model \n",
    "\n",
    "Aproach 1\n",
    "\n",
    "**SMOTE**\n",
    "\n",
    "This method addresses data imbalance by generating synthetic samples for the minority class.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precios_gas = data[\"price\"]\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot(precios_gas, notch=True, vert=True, patch_artist=True, showmeans=True)\n",
    "plt.title('Boxplot de Precios')\n",
    "plt.ylabel('Precio')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outliers were checked manually throught the data source, and we could confirmed that they are not outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = data['price'].quantile(0.25)\n",
    "Q2 = data['price'].quantile(0.5)  # Esta es la mediana\n",
    "Q3 = data['price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "upper_whisker = (Q3 + 1.5 * IQR)\n",
    "print(upper_whisker)\n",
    "\n",
    "data[data[\"price\"]>upper_whisker][[\"price\", \"brand\"]].sort_values(by='price', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gas , Numerical variables selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_gas_numerical_columns(numerical_columns: pd.DataFrame) -> pd.DataFrame:\n",
    "    #fill the elemental columns that has a minor amount of missing data with the mode\n",
    "    numerical_columns = Data_processor.fill_na_with_mode(numerical_columns, \"dimensions.length\")\n",
    "    numerical_columns = Data_processor.fill_na_with_mode(numerical_columns, \"dimensions.height\")\n",
    "\n",
    "    #fill the missing data witch regression, the parameters were based on the relation matrix \n",
    "    numerical_columns = Data_processor.impute_with_linear_regression(data=numerical_columns, x_columns=[\"dimensions.length\", \"dimensions.height\"], y_column=\"dimensions.width\")\n",
    "    numerical_columns = Data_processor.impute_with_linear_regression(data=numerical_columns, x_columns=[\"dimensions.length\", \"dimensions.height\", \"dimensions.width\"], y_column=\"trunkCapacityInLiters\")\n",
    "    numerical_columns = Data_processor.impute_with_linear_regression(data=numerical_columns, x_columns=[\"power_cv\", \"power_kw\"], y_column=\"maxSpeed\")\n",
    "    numerical_columns = Data_processor.impute_with_linear_regression(data=numerical_columns, x_columns=[\"power_cv\", \"power_kw\", \"maxSpeed\"], y_column=\"acceleration\")\n",
    "    numerical_columns = Data_processor.impute_with_linear_regression(data=numerical_columns, x_columns=[\"power_cv\", \"power_kw\", \"maxSpeed\"], y_column=\"acceleration\")\n",
    "    numerical_columns = Data_processor.impute_with_linear_regression(data=numerical_columns, x_columns=[\"Llantas_Diametro_cm\", \"power_kw\"], y_column=\"max_torque_nm\")\n",
    "\n",
    "    numerical_columns.dropna(axis=1, inplace=True)\n",
    "    return numerical_columns\n",
    "\n",
    "def get_gas_numerical_columns (data: pd.DataFrame) -> pd.DataFrame:\n",
    "    numerical_columns = data.select_dtypes(include=['number'])\n",
    "    numerical_columns.drop(columns=[ \"car_id\"], inplace=True)\n",
    "\n",
    "    #if all the values of the numerical columns is 0, we remove the column\n",
    "    cols_to_drop = numerical_columns.columns[(numerical_columns == 0).all()]\n",
    "    numerical_columns = numerical_columns.drop(cols_to_drop, axis=1)\n",
    "\n",
    "    #Remove the column with all NAs\n",
    "    max_nans = 6586\n",
    "    thresh = numerical_columns.shape[0] - max_nans\n",
    "\n",
    "    numerical_columns.dropna(axis=1, thresh=thresh+1, inplace=True)\n",
    "    return fill_gas_numerical_columns(numerical_columns)\n",
    "\n",
    "def get_gas_categorical_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ret = df.select_dtypes(include=['category'])\n",
    "    ret = ret.drop(columns=[\"environmentalLabel\"]) #All of the cars of this dataframes are electrical which implies 0 emission\n",
    "    ret = Data_processor.remove_redundand_columns(ret)\n",
    "    ret = Data_processor.impute_categorical_mode(df=ret, X=[\"brand\", \"model\"], Y=\"version\")\n",
    "    ret = Data_processor.impute_categorical_mode(df=ret, X=[\"brand\", \"model\"], Y=\"jato_classification\")\n",
    "    ret = Data_processor.impute_categorical_mode(df=ret, X=[\"brand\", \"model\", \"traction\"], Y=\"brakes\")\n",
    "    ret = Data_processor.impute_categorical_mode(df=ret, X=[\"brand\", \"model\", \"traction\",\"brakes\"], Y=\"front_suspension\")\n",
    "    ret = Data_processor.impute_categorical_mode(df=ret, X=[\"brand\", \"model\", \"traction\",\"brakes\"], Y=\"rear_suspension\")\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = get_gas_numerical_columns(data)\n",
    "categorical_columns = get_gas_categorical_columns(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = numerical_columns.corr()[\"price\"]\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df_scaled  = scaler.fit_transform(numerical_columns)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(df_scaled)\n",
    "df_pca = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biplot(score, coeff, labels=None):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    origin = [0, 0]  # Origen de las flechas\n",
    "\n",
    "    # Dibujar las flechas\n",
    "    for i in range(len(coeff)):\n",
    "        plt.arrow(origin[0], origin[1], coeff[i,0], coeff[i,1], color='r', alpha=0.5, head_width=0.05, head_length=0.1)\n",
    "        if labels is not None:\n",
    "            plt.text(coeff[i,0]*1.15, coeff[i,1]*1.15, labels[i], color='blue', ha='center', va='center')\n",
    "\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.title(\"Biplot\")\n",
    "    plt.grid(True)\n",
    "    plt.axhline(0, color='black',linewidth=0.5)\n",
    "    plt.axvline(0, color='black',linewidth=0.5)\n",
    "    plt.xlim(min(coeff[:,0])*1.2, max(coeff[:,0])*1.2)\n",
    "    plt.ylim(min(coeff[:,1])*1.2, max(coeff[:,1])*1.2)\n",
    "    plt.show()\n",
    "\n",
    "# Llamada a la funciÃ³n biplot\n",
    "biplot(principal_components, np.transpose(pca.components_[0:2, :]), labels=numerical_columns.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CART regression with only numerical values\n",
    "\n",
    "- Using only numerical values we can use the SMOTE technique to generate synthetic value data and rebalance our unbalance dataset.\n",
    "\n",
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = numerical_columns.drop(columns=[\"price_categ\",\"price\"]) # + price_categ\n",
    "y = numerical_columns[\"price_categ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split Before Applying SMOTE\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the CART Model (Decision Tree) on Resampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Cell 7: Evaluate the Model\n",
    "# Print classification report and confusion matrix\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After analyzing the results obtained with and without the application of SMOTE, it was observed that models trained without SMOTE demonstrated superior performance in terms of accuracy and stability. Although SMOTE is an effective technique for balancing imbalanced datasets by synthesizing new samples, in this specific case, the models without SMOTE outperformed those with it. \n",
    "\n",
    "**Therefore future models will be trained without SMOTE from this point forward.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_classification(y_test, y_pred):\n",
    "    result = pd.DataFrame({\"Real\": y_test, \"Prediction\": y_pred})\n",
    "    result[\"diff\"] = result[\"Real\"] - result[\"Prediction\"]\n",
    "    Evaluator.eval_ordinal_classification(diff=abs(result[\"diff\"]))\n",
    "\n",
    "def classify(X_train, X_test, y_train, y_test , classifier, classifier_name = None) -> None:\n",
    "    classifier = classifier\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting the test set results\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    eval_classification(y_test, y_pred)\n",
    "\n",
    "    if classifier_name != None:\n",
    "        return Evaluator.eval_classification(y_pred = y_pred,  y_true=y_test, binary_classification=False, classifier_name=classifier_name)\n",
    "    return Evaluator.eval_classification(y_pred = y_pred, y_true=y_test, binary_classification=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gas_cars = pd.merge(numerical_columns, categorical_columns, left_index=True, right_index=True, how='inner')\n",
    "numerical_column_names = list(numerical_columns.columns)\n",
    "categorical_column_names = list(categorical_columns.columns)\n",
    "\n",
    "target = gas_cars[[\"price\", \"price_categ\"]]\n",
    "gas_cars.drop(columns=[\"price\"], inplace=True)\n",
    "\n",
    "numerical_column_names.remove(\"price\")\n",
    "\n",
    "\n",
    "encoders_and_scalers = {}\n",
    "for column in numerical_column_names:\n",
    "    scaler = StandardScaler()\n",
    "    gas_cars[[column]] = scaler.fit_transform(gas_cars[[column]])\n",
    "    encoders_and_scalers[column] = scaler \n",
    "\n",
    "gas_cars_encoded = pd.get_dummies(gas_cars, columns=categorical_column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(X_train, X_test, y_train, y_test, DecisionTreeClassifier(random_state=42), classifier_name=\"CART\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest\n",
    "Random forest can get a better result at a higher computational time cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(X_train, X_test, y_train, y_test, RandomForestClassifier(random_state=42), classifier_name=\"RandomForestClassifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM\n",
    "Much higher computational cost, more distributed error, but in overall worse result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(X_train_resampled, X_test, y_train_resampled, y_test, SVC(random_state=42), classifier_name=\"SVC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(X_train, X_test, y_train, y_test, SVC(random_state=42), classifier_name=\"SVC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(X_train, X_test, y_train, y_test, GaussianNB(), classifier_name=\"Naive bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_encoded = encoder.fit_transform(data[['price_categ']])\n",
    "\n",
    "# Step 2: Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    gas_cars_encoded, y_encoded, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Step 3: Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Step 4: Define the ANN model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(64, activation='tanh'))\n",
    "model.add(Dense(32, activation='tanh'))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))  # Softmax for multi-class classification\n",
    "\n",
    "# Step 5: Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 6: Train the model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluator.eval_classification(y_pred=y_pred_classes, y_true=y_test_classes, binary_classification=False, classifier_name=\"ANN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(gas_cars_encoded, precios_gas, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression(X_train, X_test, y_train, y_test , regressor, regressor_name = None) -> None:\n",
    "    regressor = regressor\n",
    "    regressor.fit(X_train, y_train)\n",
    "    # Predicting the test set results\n",
    "    y_pred = regressor.predict(X_test)\n",
    "\n",
    "    if regressor_name != None:\n",
    "        Evaluator.eval_regression(y_pred = y_pred, bins=5, y_true=y_test, plot=False, n_features=X_train.shape[1], regressor_name=regressor_name)\n",
    "    Evaluator.eval_regression(y_pred = y_pred, y_true=y_test, plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression(X_train, X_test, y_train, y_test , DecisionTreeRegressor(random_state=42), regressor_name=\"CART\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cart Optimized Hyperparameters with Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression(X_train, X_test, y_train, y_test , RandomForestRegressor(random_state=42), regressor_name=\"RandomForest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression(X_train, X_test, y_train, y_test , SVR(kernel='rbf'), regressor_name=\"SVR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariable regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regressor = LinearRegression()\n",
    "linear_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the test set results\n",
    "y_pred = linear_regressor.predict(X_test)\n",
    "\n",
    "# Optionally, display the coefficients of the model\n",
    "print(\"Coefficients:\", linear_regressor.coef_)\n",
    "print(\"Intercept:\", linear_regressor.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\"Real\": y_test, \"Prediction\": y_pred})\n",
    "result[\"diff\"] = result[\"Real\"].to_numpy() - result[\"Prediction\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='linear'))\n",
    "model.add(Dense(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, mae = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Mean Absolute Error on test set: {mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss curve\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Model Loss Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluator.eval_regression(y_pred=y_pred, y_true=y_test, plot=False, n_features=X_train.shape[1], regressor_name=\"ANN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluator.save(\"gas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tunning and Custering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = MasterGenerator(X=gas_cars_encoded.drop(columns=[\"price_categ\"]), y_categ=target[\"price_categ\"], y_numeric=precios_gas, n_tries=128, CUML=True, name=\"HP_gas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master.generate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
