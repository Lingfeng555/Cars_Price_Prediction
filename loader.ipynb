{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "We import some neccesary libraries and download some global scope data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\marti\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import ast\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Datsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_22600\\2912694450.py:12: DtypeWarning: Columns (40,41,44,45,46,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_22600\\2912694450.py:12: DtypeWarning: Columns (40,41,44,45,46,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_22600\\2912694450.py:12: DtypeWarning: Columns (40,41,44,45,46,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_22600\\2912694450.py:12: DtypeWarning: Columns (40,41,44,45,46,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_22600\\2912694450.py:12: DtypeWarning: Columns (40,41,44,45,46,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_22600\\2912694450.py:12: DtypeWarning: Columns (40,41,44,45,46,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_22600\\2912694450.py:12: DtypeWarning: Columns (40,41,44,45,46,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price\n",
      "km\n",
      "year\n",
      "color\n",
      "cubicCapacity\n",
      "brand\n",
      "model\n",
      "version\n",
      "fuelType\n",
      "bodyTypeId\n",
      "transmissionTypeId\n",
      "doors\n",
      "seatingCapacity\n",
      "warranty_months\n",
      "province\n",
      "environmentalLabel\n",
      "co2Emissions\n",
      "co2EmissionsGramsPerKm\n",
      "trunkCapacityInLiters\n",
      "maxSpeed\n",
      "acceleration\n",
      "hasDetails\n",
      "jato_classification\n",
      "traction\n",
      "brakes\n",
      "front_suspension\n",
      "rear_suspension\n",
      "power_cv\n",
      "power_kw\n",
      "rpm_max_power\n",
      "max_torque_nm\n",
      "rpm_max_torque\n",
      "motor_description\n",
      "transmission_description\n",
      "speakers\n",
      "trip_computer\n",
      "remote_audio_control_on_steering_wheel\n",
      "dvd_navigation\n",
      "antenna\n",
      "abs\n",
      "electronic_traction_control\n",
      "parking_sensors\n",
      "airbag\n",
      "stability_control\n",
      "curve_braking_control\n",
      "isofix_system\n",
      "start_stop_automatic\n",
      "cubicCapacity_seat_folded\n",
      "Acabado Interior_Apoyabrazos\n",
      "Acabado Interior_Asiento\n",
      "Acabado Interior_Asientos\n",
      "Acabado Interior_Dos\n",
      "Acabado Interior_Pedales\n",
      "Acabado Interior_Reloj\n",
      "Acabado Interior_Reposacabezas\n",
      "Acabado Interior_Tres\n",
      "Acabado Interior_Uno\n",
      "Confort_Aire\n",
      "Confort_Apertura\n",
      "Confort_Aviso\n",
      "Confort_Banda\n",
      "Confort_Calefacción\n",
      "Confort_Cierre\n",
      "Confort_Compartimentos\n",
      "Confort_Control\n",
      "Confort_Dirección\n",
      "Confort_Dos\n",
      "Confort_Elevalunas\n",
      "Confort_Faros\n",
      "Confort_Indicador\n",
      "Confort_Inmovilizador\n",
      "Confort_Inmovilizador\n",
      "\n",
      "Confort_Intermitentes\n",
      "Confort_Lavafaros\n",
      "Confort_Lavafaros\n",
      "\n",
      "Confort_Limpiaparabrisas\n",
      "Confort_Llave\n",
      "Confort_Luces\n",
      "Confort_Luz\n",
      "Confort_Memoria\n",
      "Confort_Protección\n",
      "Confort_Regulación\n",
      "Confort_Sistema\n",
      "Confort_Tapa\n",
      "Confort_Tarjeta\n",
      "Confort_Techo\n",
      "Confort_Testigo\n",
      "Confort_Una\n",
      "Confort_Volante\n",
      "Acabado Exterior_Alerón\n",
      "Acabado Exterior_Cristales\n",
      "Acabado Exterior_Defensa\n",
      "Acabado Exterior_Faldones\n",
      "Acabado Exterior_Guardabarros\n",
      "Acabado Exterior_Llantas\n",
      "Acabado Exterior_Maletero\n",
      "Acabado Exterior_Molduras\n",
      "Acabado Exterior_Neumáticos\n",
      "Acabado Exterior_Pasos\n",
      "Acabado Exterior_Pintura\n",
      "Acabado Exterior_Puerta\n",
      "Acabado Exterior_Retrovisor\n",
      "Acabado Exterior_Rueda\n",
      "consumption.urban\n",
      "consumption.mixed\n",
      "consumption.extraUrban\n",
      "dimensions.width\n",
      "dimensions.height\n",
      "dimensions.length\n",
      "electricFeatures.powerSource.batteryType\n",
      "electricFeatures.powerSource.batteryVoltage.value\n",
      "electricFeatures.powerSource.batteryVoltage.unit\n",
      "electricFeatures.powerSource.maximumBatteryKWH.value\n",
      "electricFeatures.powerSource.maximumBatteryKWH.unit\n",
      "electricFeatures.power.maxPower.value\n",
      "electricFeatures.power.maxPower.unit\n",
      "electricFeatures.chargingInformation.standardMode.scenario\n",
      "electricFeatures.chargingInformation.standardMode.duration.value\n",
      "electricFeatures.chargingInformation.standardMode.duration.unit\n",
      "electricFeatures.chargingInformation.standardMode.amps.value\n",
      "electricFeatures.chargingInformation.standardMode.amps.unit\n",
      "electricFeatures.chargingInformation.fastMode.scenario\n",
      "electricFeatures.chargingInformation.fastMode.duration.value\n",
      "electricFeatures.chargingInformation.fastMode.duration.unit\n",
      "electricFeatures.chargingInformation.fastMode.maxKW.value\n",
      "electricFeatures.chargingInformation.fastMode.maxKW.unit\n",
      "electricFeatures.chargingInformation.fastMode.chargeEnd.value\n",
      "electricFeatures.chargingInformation.fastMode.chargeEnd.unit\n",
      "electricFeatures.motorType\n",
      "electricFeatures.chargingConnector\n",
      "electricFeatures.combinedConsumption.value\n",
      "electricFeatures.combinedConsumption.unit\n",
      "electricFeatures.combinedConsumption.testType\n",
      "electricFeatures.range.value\n",
      "electricFeatures.range.unit\n",
      "electricFeatures.powerSource.onboardCharger.value\n",
      "electricFeatures.powerSource.onboardCharger.unit\n",
      "electricFeatures.chargingInformation.standardMode.voltage.value\n",
      "electricFeatures.chargingInformation.standardMode.voltage.unit\n",
      "electricFeatures.chargingInformation.standardMode.chargeStart.value\n",
      "electricFeatures.chargingInformation.standardMode.chargeStart.unit\n",
      "electricFeatures.chargingInformation.standardMode.chargeEnd.value\n",
      "electricFeatures.chargingInformation.standardMode.chargeEnd.unit\n",
      "electricFeatures.chargingInformation.fastMode.chargeStart.value\n",
      "electricFeatures.chargingInformation.fastMode.chargeStart.unit\n",
      "electricFeatures.chargingInformation.fastMode.voltage.value\n",
      "electricFeatures.chargingInformation.fastMode.voltage.unit\n",
      "electricFeatures.chargingInformation.standardMode.maxKW.value\n",
      "electricFeatures.chargingInformation.standardMode.maxKW.unit\n",
      "electricFeatures.chargingInformation.fastMode.amps.value\n",
      "electricFeatures.chargingInformation.fastMode.amps.unit\n",
      "idx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def merge_csv_files_from_folder(folder_path):\n",
    "    # Lista para almacenar los DataFrames\n",
    "    df_list = []\n",
    "\n",
    "    # Recorrer todos los archivos en la carpeta\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.csv'):\n",
    "            # Obtener la ruta completa del archivo\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            \n",
    "            # Leer el archivo CSV y agregarlo a la lista de DataFrames\n",
    "            df = pd.read_csv(file_path)\n",
    "            df_list.append(df)\n",
    "\n",
    "    # Concatenar todos los DataFrames en uno solo\n",
    "    if df_list:\n",
    "        merged_df = pd.concat(df_list, ignore_index=True)\n",
    "        return merged_df\n",
    "    else:\n",
    "        print(\"No se encontraron archivos CSV en la carpeta.\")\n",
    "        return pd.DataFrame()  \n",
    "\n",
    "data = merge_csv_files_from_folder(\"data_processed/csv/\")\n",
    "data.drop(columns=\"car_id\", inplace=True)\n",
    "colnames = data.columns.to_list()\n",
    "for col in colnames: print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_boolean(value):\n",
    "    if value == \"True\":\n",
    "        return True\n",
    "    elif value == \"False\":\n",
    "        return False\n",
    "    else:\n",
    "        return value\n",
    "for colum in [40,41,44,45,46,47]: data.iloc[:, colum] = data.iloc[:, colum].apply(lambda x: convert_boolean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dirty_columns(prefix): return [col for col in data.columns if prefix in col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Dirty Columns\n",
    "\n",
    "There are four columns that require cleaning: `^Confort_`, `^Acabado Interior_` (already cleaned), `^Acabado Exterior_`, and `^electricFeatures`. You need to select one of these columns and process the data until it becomes readable. All columns should carry meaningful information. If a column contains a wide range of phrases, you can merge them into a single column labeled as \"description,\" which will allow the application of NLP techniques later.\n",
    "\n",
    "### Guidelines for Cleaning:\n",
    "\n",
    "- **Singular and Plural Forms**:  \n",
    "  If two columns represent the same feature, but one is the plural form of the other (e.g., `Confort_Luz` and `Confort_Luces`), discard the plural column.\n",
    "\n",
    "- **Duplicate Column Names**:  \n",
    "  If two columns share the same name, you can discard one of them.\n",
    "\n",
    "- **Numbered Columns**:  \n",
    "  If multiple columns are part of a series ending with a number (e.g., `Confort_Dos`, `Confort_Uno`), they likely describe different aspects of a single feature. In this case, merge them into a single column.\n",
    "\n",
    "- **Relevance of Columns**:  \n",
    "  Most of the dirty columns have names that describe the feature of their information, but some columns may be irrelevant.\n",
    "\n",
    "- **Example for Reference**:  \n",
    "  The column `^Acabado Interior_` has already been cleaned and can serve as an example of how to approach the cleaning process.\n",
    "\n",
    "- **Nan and \"no tiene\"**:  \n",
    "  Some data has an Nan and \"no tiene\", the first one means that we don't know the data but probably you can deduce that feature with other columns, specially in electrical features, and the second the car does nor have that feature.\n",
    "\n",
    "**Data Types**:\n",
    "  BE CAREFULL most of the cells that contains \" ['Asiento de... \" is a string not a list\n",
    "  \n",
    "At the beginning of each section, you will find a printout of the columns that need to be cleaned.\n",
    "\n",
    "---\n",
    "\n",
    "Let me know if you need further revisions or clarification!\n",
    "\n",
    "\n",
    "## ~~Profe~~ **Lingfeng** te hacia `ilu` escribir esto no ? `XD` \n",
    "\n",
    "o espera\n",
    "\n",
    "Prof Lingfeng you enjoyed writing this, right? XD \n",
    "\n",
    "of course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(lista, elemento): return [x for x in lista if x != elemento]\n",
    "\n",
    "def check_unique_values(column):\n",
    "    ret = sorted(set(data[column].to_list()))\n",
    "    print(f\"Column: {column}\")\n",
    "    for x in ret: print(f'{x}: {data[column].to_list().count(x)}')\n",
    "    print(f'NA: {data[column].to_list().count(None)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Confort\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confort_Aire\n",
      "Confort_Apertura\n",
      "Confort_Aviso\n",
      "Confort_Banda\n",
      "Confort_Calefacción\n",
      "Confort_Cierre\n",
      "Confort_Compartimentos\n",
      "Confort_Control\n",
      "Confort_Dirección\n",
      "Confort_Dos\n",
      "Confort_Elevalunas\n",
      "Confort_Faros\n",
      "Confort_Indicador\n",
      "Confort_Inmovilizador\n",
      "Confort_Inmovilizador\n",
      "\n",
      "Confort_Intermitentes\n",
      "Confort_Lavafaros\n",
      "Confort_Lavafaros\n",
      "\n",
      "Confort_Limpiaparabrisas\n",
      "Confort_Llave\n",
      "Confort_Luces\n",
      "Confort_Luz\n",
      "Confort_Memoria\n",
      "Confort_Protección\n",
      "Confort_Regulación\n",
      "Confort_Sistema\n",
      "Confort_Tapa\n",
      "Confort_Tarjeta\n",
      "Confort_Techo\n",
      "Confort_Testigo\n",
      "Confort_Una\n",
      "Confort_Volante\n"
     ]
    }
   ],
   "source": [
    "confort_columns = find_dirty_columns(\"Confort\")\n",
    "for x in confort_columns: print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_ac_zones(val):\n",
    "    cleaned_val = re.sub(r\"[\\[\\]']\", '', val).strip().lower()\n",
    "\n",
    "    match cleaned_val:\n",
    "        case val if 'bizona' in val:\n",
    "            return 'BIZONA'\n",
    "        case val if 'trizona' in val or '3 zonas' in val:\n",
    "            return 'TRIZONA'\n",
    "        case val if '4 zonas' in val:\n",
    "            return 'TETRAZONA'\n",
    "        case _:\n",
    "            return 'MONOZONA' \n",
    "        \n",
    "def classify_ac_type(val): \n",
    "    cleaned_val = re.sub(r\"[\\[\\]']\", '', val).strip().lower()\n",
    "    match cleaned_val:\n",
    "        case val if 'semi-auto' in val or 'semi-automático' in val or 'semi-automatico' in val:\n",
    "            return 'SEMIAUTO'\n",
    "        case val if 'automático' in val or 'auto' in val or 'automatico' in val:\n",
    "            return 'AUTO'\n",
    "        case val if 'manual' in val:\n",
    "            return 'MANUAL'\n",
    "        case val if 'no tiene' in val:\n",
    "            return 'NO_TIENE'\n",
    "        case _:\n",
    "            return 'STANDARD'  \n",
    "        \n",
    "def extraer_numero_tcinturones(text):\n",
    "    if 'un' in text: return 1\n",
    "    elif 'dos' in text:return 2\n",
    "    elif 'tres' in text:return 3\n",
    "    elif 'cuatro' in text:return 4\n",
    "    elif 'cinco' in text:return 5\n",
    "    elif 'seis' in text:return 6\n",
    "    elif 'siete' in text:return 7\n",
    "    elif 'Testigo' in text: return 2\n",
    "    else: return 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_22600\\2351505979.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"Techo_Deslizante\"] = data[\"Confort_Techo\"].apply(lambda x:\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_22600\\2351505979.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"Control_Remoto\"] = data[\"Confort_Techo\"].apply(lambda x:\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_22600\\2351505979.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"Testigo_Cinturones\"] = data[\"Confort_Testigo\"].apply(lambda x:\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_22600\\2351505979.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"Numero_Testigos\"] = data[\"Confort_Testigo\"].apply(extraer_numero_tcinturones)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_22600\\2351505979.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"Confort_Volante_Descripción\"] = data[\"Confort_Volante\"]\n"
     ]
    }
   ],
   "source": [
    "#Confort Aire\n",
    "data[\"AC_Zones\"] = data[\"Confort_Aire\"].apply(classify_ac_zones)\n",
    "data[\"AC_Type\"] = data[\"Confort_Aire\"].apply(classify_ac_type) \n",
    "\n",
    "#Confort_Apertura\n",
    "#El maletero se abre a distancia? (Mecanicamente o electricamente)\n",
    "data[\"trunk_auto_open\"] = data[\"Confort_Apertura\"].apply(lambda x: False if 'no tiene' in x else True)\n",
    "\n",
    "#Se podría quitar la verdad\n",
    "data[\"BandaTintada\"] = data[\"Confort_Banda\"].apply(lambda x: False if 'no tiene' in x else True)\n",
    "\n",
    "data[\"Calefacción_Trasera\"] = data[\"Confort_Calefacción\"].apply(lambda x: False if 'no tiene' in x else True)\n",
    "\n",
    "\n",
    "data['Doble_Cierre'] = data['Confort_Cierre'].apply(lambda x: True if 'doble cierre' in x else False)\n",
    "data['Movil_NFC'] = data['Confort_Cierre'].apply(lambda x: True if 'teléfono móvil' in x or 'NFC' in x else False)\n",
    "data['Metodo_Apertura'] = data['Confort_Cierre'].apply(\n",
    "   lambda x: 'Mando a distancia' if 'mando a distancia' in x else\n",
    "              'Tarjeta/llave inteligente' if 'tarjeta/llave inteligente' in x else\n",
    "              'Llave' if 'llave' in x else\n",
    "              'Teléfono móvil' if 'teléfono móvil' in x else\n",
    "              'Desconocido'\n",
    ")\n",
    "\n",
    "\n",
    "data[\"Control_Crucero\"] = data[\"Confort_Control\"].apply(lambda x: True if 'crucero' in x else False)\n",
    "data[\"Control_Crucero_Adaptativo\"] = data[\"Confort_Control\"].apply(lambda x: True if 'adaptativo' in x else False)  \n",
    "data[\"SensoresDistancia\"] = data[\"Confort_Control\"].apply(lambda x: True if 'distancia' in x else False)\n",
    "data[\"StopGo\"] = data[\"Confort_Control\"].apply(lambda x: True if 'stop' in x else False)\n",
    "\n",
    "\n",
    "data[\"Dirección_Asistida\"] = data[\"Confort_Dirección\"].apply(lambda x: True if 'dirección asistida' in x.lower() else False)\n",
    "data[\"Dirección_Electrica\"] = data[\"Confort_Dirección\"].apply(lambda x: True if 'eléctrica' in x.lower() else False)\n",
    "data[\"Endurecimiento_Progresivo\"] = data[\"Confort_Dirección\"].apply(lambda x: True if 'endurecimiento progresivo' in x.lower() else False)\n",
    "data[\"Desmultiplicacion_Variable\"] = data[\"Confort_Dirección\"].apply(lambda x: True if 'desmultiplicación variable' in x.lower() else False)\n",
    "data[\"Dirección_Electro_Hidraulica\"] = data[\"Confort_Dirección\"].apply(lambda x: True if 'electro-hidráulica' in x.lower() else False)\n",
    "\n",
    "\n",
    "data[\"Elevalunas_Electricos\"] = data[\"Confort_Elevalunas\"].apply(lambda x: True if 'elevalunas eléctricos' in x.lower() else False)\n",
    "data[\"Un_Solo_Toque\"] = data[\"Confort_Elevalunas\"].apply(lambda x: True if 'uno de ellos de un solo toque' in x.lower() or 'dos de ellos de un solo toque' in x.lower() else False)\n",
    "data[\"Elevalunas_Traseros\"] = data[\"Confort_Elevalunas\"].apply(lambda x: True if 'traseros' in x.lower() else False)\n",
    "\n",
    "\n",
    "data[\"Tipo_Faro\"] = data[\"Confort_Faros\"].apply(lambda x: \n",
    "    'LED' if 'led' in x.lower() else\n",
    "    'Xenón' if 'xenón' in x.lower() else\n",
    "    'Halógeno' if 'halógeno' in x.lower() else\n",
    "    'Otro')\n",
    "data[\"Luz_Larga\"] = data[\"Confort_Faros\"].apply(lambda x: True if 'luz larga' in x.lower() else False)\n",
    "data[\"Faros_Dobles\"] = data[\"Confort_Faros\"].apply(lambda x: True if 'dobles' in x.lower() else False)\n",
    "\n",
    "\n",
    "data[\"Indicador_Baja_Presion_Neumaticos\"] = data[\"Confort_Indicador\"].apply(lambda x: \n",
    "    True if 'baja presion' in x.lower() else False)\n",
    "data[\"Visualizacion_Presion\"] = data[\"Confort_Indicador\"].apply(lambda x: \n",
    "    True if 'visualización de presión' in x.lower() else False)\n",
    "data[\"Indicador_Consumo\"] = data[\"Confort_Indicador\"].apply(lambda x: \n",
    "    True if 'indicador de consumo' in x.lower() else False)\n",
    "\n",
    "\n",
    "data[\"Inmovilizador\"] = data[\"Confort_Inmovilizador\"].apply(lambda x: \n",
    "    True if 'Inmovilizador' in x else False)\n",
    "\n",
    "\n",
    "data[\"Intermitentes_Laterales\"] = data[\"Confort_Intermitentes\"].apply(lambda x:\n",
    "    True if 'laterales' in x else False)\n",
    "\n",
    "\n",
    "data[\"Lavafaros\"] = data[\"Confort_Lavafaros\"].apply(lambda x:\n",
    "    True if 'Lavafaros' in x else False)\n",
    "\n",
    "\n",
    "data[\"Sensor_Lluvia\"] = data[\"Confort_Limpiaparabrisas\"].apply(lambda x: \n",
    "    True if 'sensor de lluvia' in x.lower() else False)\n",
    "data[\"Intermitencia_Automatica\"] = data[\"Confort_Limpiaparabrisas\"].apply(lambda x: \n",
    "    True if 'intermitencia automática' in x.lower() else False)\n",
    "\n",
    "\n",
    "data[\"Luces_Lectura\"] = data[\"Confort_Luces\"].apply(lambda x: \n",
    "    True if 'luces de lectura' in x.lower() else False)\n",
    "data[\"Luces_Antiniebla\"] = data[\"Confort_Luces\"].apply(lambda x: \n",
    "    True if 'luces antiniebla' in x.lower() else False)\n",
    "data[\"Luces_Cortesía\"] = data[\"Confort_Luces\"].apply(lambda x: \n",
    "    True if 'luces de cortesía' in x.lower() else False)\n",
    "data[\"Luces_Laterales\"] = data[\"Confort_Luces\"].apply(lambda x: \n",
    "    True if 'luces laterales maniobras' in x.lower() else False)\n",
    "\n",
    "\n",
    "data[\"Memoria_Asientos\"] = data[\"Confort_Memoria\"].apply(lambda x: \n",
    "    True if 'posición' in x else False)\n",
    "\n",
    "\n",
    "data[\"Techo_Electrico\"] = data[\"Confort_Techo\"].apply(lambda x: \n",
    "    True if 'eléctrico' in x.lower() else False)\n",
    "data[\"Techo_Inclinable\"] = data[\"Confort_Techo\"].apply(lambda x: \n",
    "    True if 'inclinable' in x.lower() else False)\n",
    "data[\"Techo_Deslizante\"] = data[\"Confort_Techo\"].apply(lambda x: \n",
    "    True if 'deslizante' in x.lower() else False)\n",
    "data[\"Control_Remoto\"] = data[\"Confort_Techo\"].apply(lambda x: \n",
    "    True if 'control remoto' in x.lower() else False)\n",
    "\n",
    "data[\"Testigo_Cinturones\"] = data[\"Confort_Testigo\"].apply(lambda x: \n",
    "    True if 'testigo de cinturones' in x.lower() else False)\n",
    "\n",
    "data[\"Numero_Testigos\"] = data[\"Confort_Testigo\"].apply(extraer_numero_tcinturones)\n",
    "\n",
    "\n",
    "# Feed para el modelo NLP\n",
    "data[\"Confort_Volante_Descripción\"] = data[\"Confort_Volante\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminar todas las columas con descripciones iniciales\n",
    "for col in confort_columns: \n",
    "    data.drop(columns=col, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Acabado Interior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "acabado_interior_columns = find_dirty_columns(\"Acabado Interior\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "acabado_interior_columns.remove(\"Acabado Interior_Asientos\")\n",
    "data.drop(columns=\"Acabado Interior_Asientos\", inplace=True)\n",
    "\n",
    "#for x in acabado_interior_columns: print(x)\n",
    "#data[acabado_interior_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_22600\\950979874.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"sports_pedals\"] = data[\"Acabado Interior_Pedales\"].apply(convert_sports_pedals)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_22600\\950979874.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"interior_clock\"] = data[\"Acabado Interior_Reloj\"].apply(convert_interior_clock)\n"
     ]
    }
   ],
   "source": [
    "# Definir funciones personalizadas para la conversión\n",
    "def convert_sports_pedals(value):\n",
    "    if value == \"['Pedales deportivos']\":\n",
    "        return True\n",
    "    elif value == 'no tiene':\n",
    "        return False\n",
    "    else:\n",
    "        return None  # Por si hay otros valores\n",
    "\n",
    "def convert_interior_clock(value):\n",
    "    if value == \"['Reloj analógico']\":\n",
    "        return 'analogico'\n",
    "    elif value == \"['Reloj digital']\":\n",
    "        return 'digital'\n",
    "    elif value == \"['Reloj']\":\n",
    "        return 'regular'\n",
    "    elif value == \"no tiene\":\n",
    "        return 'no tiene'\n",
    "    else:\n",
    "        return None  # Por si hay otros valores\n",
    "\n",
    "# Aplicar las funciones a las columnas correspondientes\n",
    "data[\"sports_pedals\"] = data[\"Acabado Interior_Pedales\"].apply(convert_sports_pedals)\n",
    "data[\"interior_clock\"] = data[\"Acabado Interior_Reloj\"].apply(convert_interior_clock)\n",
    "\n",
    "#check_unique_values(\"sports_pedals\")\n",
    "#check_unique_values(\"interior_clock\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: arm_suppport_front\n",
      "Tiene: 117241\n",
      "abatible: 98\n",
      "ajustable: 1\n",
      "caja integrada: 4238\n",
      "no tiene: 43859\n",
      "NA: 0\n",
      "Column: arm_suppport_back\n",
      "Tiene: 64993\n",
      "abatible: 5\n",
      "acceso maletero: 406\n",
      "ajustable: 2\n",
      "caja integrada: 1415\n",
      "caja integrada acceso maletero: 559\n",
      "no tiene: 98057\n",
      "NA: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def process_arm_suppport_front(phrases: list) -> str:\n",
    "    stop_words = set(stopwords.words('spanish'))\n",
    "    stop_words.add(\",\")\n",
    "    text = \" # \".join(phrases)\n",
    "    if not ('delantero' in text): return (\"no tiene\")\n",
    "    text = [word for word in text.split() if word not in stop_words]\n",
    "    if '#' in text: \n",
    "        ret = \" \".join( text[ (text.index('delantero')+1):text.index('#')] )\n",
    "        return \"Tiene\" if len(ret) == 0 else ret\n",
    "    else: \n",
    "        ret = \" \".join( text[(text.index('delantero')+1):len(text)] ) \n",
    "        return \"Tiene\" if len(ret) == 0 else ret\n",
    "\n",
    "def process_arm_suppport_back(phrases: list) -> str:\n",
    "    stop_words = set(stopwords.words('spanish'))\n",
    "    stop_words.add(\",\")\n",
    "    text = \" # \".join(phrases)\n",
    "    if not ('trasero' in text): return (\"no tiene\")\n",
    "\n",
    "    text = [word for word in text.split() if word not in stop_words]\n",
    "\n",
    "    ret = \" \".join( text[(text.index('trasero')+1):len(text)] ) \n",
    "    return \"Tiene\" if len(ret) == 0 else ret \n",
    "\n",
    "arm_suppport_front = data[\"Acabado Interior_Apoyabrazos\"].apply(lambda x: x if x == 'no tiene' else process_arm_suppport_front(eval(x)) )\n",
    "arm_suppport_back = data[\"Acabado Interior_Apoyabrazos\"].apply(lambda x: x if x == 'no tiene' else process_arm_suppport_back(eval(x)) )\n",
    "\n",
    "data = pd.concat([data, arm_suppport_front.rename(\"arm_suppport_front\"), arm_suppport_back.rename(\"arm_suppport_back\")], axis=1)\n",
    "\n",
    "check_unique_values(\"arm_suppport_front\")\n",
    "check_unique_values(\"arm_suppport_back\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_seat_description(phrases: list) -> str: return \". \".join(phrases)\n",
    "\n",
    "data[\"seat_description\"] = data[\"Acabado Interior_Asiento\"].apply( lambda x: x if x == 'no tiene' else process_seat_description(eval(x)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Acabado Interior_Uno\"] = data[\"Acabado Interior_Uno\"].apply( lambda x: \"['no tiene']\" if x == 'no tiene' else x )\n",
    "data[\"Acabado Interior_Dos\"] = data[\"Acabado Interior_Dos\"].apply( lambda x: \"['no tiene']\" if x == 'no tiene' else x )\n",
    "data[\"Acabado Interior_Tres\"] = data[\"Acabado Interior_Tres\"].apply( lambda x: \"['no tiene']\" if x == 'no tiene' else x )\n",
    "data[\"Acabado Interior_Reposacabezas\"] = data[\"Acabado Interior_Reposacabezas\"].apply( lambda x: \"['no tiene']\" if x == 'no tiene' else x )\n",
    "\n",
    "data[\"Acabado Interior_Uno\"] = data[\"Acabado Interior_Uno\"].apply(ast.literal_eval)\n",
    "data[\"Acabado Interior_Dos\"] = data[\"Acabado Interior_Dos\"].apply(ast.literal_eval)\n",
    "data[\"Acabado Interior_Tres\"] = data[\"Acabado Interior_Tres\"].apply(ast.literal_eval)\n",
    "data[\"Acabado Interior_Reposacabezas\"] = data[\"Acabado Interior_Reposacabezas\"].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['head_supporter'] = data.apply(\n",
    "    lambda row: \". \".join(\n",
    "        remove_duplicates(row[\"Acabado Interior_Uno\"] + row[\"Acabado Interior_Dos\"] + row[\"Acabado Interior_Tres\"] + row[\"Acabado Interior_Reposacabezas\"], 'no tiene')\n",
    "    ), \n",
    "    axis=1)\n",
    "#check_unique_values(\"head_supporter\")\n",
    "\n",
    "for col in acabado_interior_columns: data.drop(columns= col, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Acabado Exterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopw = frozenset(stopwords.words('spanish')) | {\",\"}\n",
    "\n",
    "def cleanTry(phrases: list) -> str:\n",
    "    if not phrases:\n",
    "        return \"no tiene\"\n",
    "    \n",
    "    text = phrases\n",
    "    \n",
    "    text = [word for word in text.split() if word.lower() not in stopw]\n",
    "\n",
    "    return \"no tiene\" if len(text) == 0 else \" \".join(text)\n",
    "\n",
    "def extract_diameter(text):\n",
    "    match = re.search(r'(\\d+(?:,\\d+)?)\\s*pulgadas\\s*diámetro', text)\n",
    "    if match:\n",
    "        return (float(match.group(1).replace(',', '.'))*2.54)\n",
    "    else:\n",
    "        return \"no tiene\"  \n",
    "    \n",
    "def clean_acabado(cell):\n",
    "    cell_cleaned = re.sub(r\"[\\[\\]']\", '', cell)\n",
    "    cell_cleaned = cell_cleaned.strip().lower()\n",
    "    cell_cleaned = re.sub(r'\\s+', ' ', cell_cleaned)\n",
    "    return cell_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=[\"Acabado Exterior_Maletero\",\"Acabado Exterior_Pasos\",\"Acabado Exterior_Maletero\",\"Acabado Exterior_Defensa\",\"Acabado Exterior_Guardabarros\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descripcion --------------------------\n",
      "Descripcion --------------------------\n",
      "Descripcion --------------------------\n",
      "Descripcion --------------------------\n",
      "Descripcion --------------------------\n",
      "Descripcion --------------------------\n",
      "Descripcion --------------------------\n",
      "Descripcion --------------------------\n",
      "Descripcion --------------------------\n",
      "Descripcion --------------------------\n",
      "Descripcion --------------------------\n"
     ]
    }
   ],
   "source": [
    "acabado_exterior_columns = find_dirty_columns(\"Acabado Exterior\")\n",
    "\n",
    "data[acabado_exterior_columns] = data[acabado_exterior_columns].apply(lambda col: col.apply(lambda x: clean_acabado(x) if x != 'no tiene' else x))\n",
    "\n",
    "data[acabado_exterior_columns] = data[acabado_exterior_columns].apply(lambda col: col.apply(lambda x: cleanTry(x) if x != 'no tiene' else x))\n",
    "\n",
    "data[\"Llantas_Diametro_cm\"] = data[\"Acabado Exterior_Llantas\"].apply(lambda x: extract_diameter(x))\n",
    "\n",
    "acabado_exterior_columns.append(\"Llantas_Diametro_cm\")\n",
    "\n",
    "\n",
    "\n",
    "for x in acabado_exterior_columns:\n",
    "    \n",
    "    #print(x)\n",
    "    print(data[x].nbytes)\n",
    "    print(\"Descripcion --------------------------\")\n",
    "    print(data[x].astype('category').nbytes)\n",
    "    #print(data[x].describe())\n",
    "    #print(\"Counts--------------------------------\")\n",
    "    #print(data[x].value_counts())\n",
    "    #print(\"CleanTry------------------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Electronic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                   Gasolina\n",
      "1                   Gasolina\n",
      "2                   Gasolina\n",
      "3                  Eléctrico\n",
      "4                    Híbrido\n",
      "                 ...        \n",
      "165432                Diésel\n",
      "165433              Gasolina\n",
      "165434               Híbrido\n",
      "165435    Híbrido enchufable\n",
      "165436              Gasolina\n",
      "Name: fuelType, Length: 165437, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data[\"fuelType\"])\n",
    "#check_unique_values(\"fuelType\") Pone que hay un float en esa columna, solucionalo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_file_size = 100 * 1024 * 1024\n",
    "output_folder = \"NLP/test_data\"\n",
    "def split_dataframe_to_csv(df, max_file_size, base_filename):\n",
    "    file_index = 1\n",
    "    chunk_size = len(df) // 7 \n",
    "    while chunk_size > 0:\n",
    "        start_row = 0\n",
    "        while start_row < len(df):\n",
    "            end_row = start_row + chunk_size\n",
    "            chunk = df.iloc[start_row:end_row]\n",
    "            filename = f\"{output_folder}/{base_filename}_part{file_index}.csv\"\n",
    "            chunk.to_csv(filename, index=False)\n",
    "            if os.path.getsize(filename) > max_file_size:\n",
    "                chunk_size //= 2\n",
    "                os.remove(filename)\n",
    "            else:\n",
    "                start_row = end_row\n",
    "                file_index += 1\n",
    "\n",
    "        if start_row >= len(df):\n",
    "            break\n",
    "\n",
    "split_dataframe_to_csv(data, max_file_size, base_filename=\"test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
