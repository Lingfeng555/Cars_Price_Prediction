{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "We import some neccesary libraries and download some global scope data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\marti\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import ast\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Datsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_18132\\2912694450.py:12: DtypeWarning: Columns (40,41,44,45,46,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_18132\\2912694450.py:12: DtypeWarning: Columns (40,41,44,45,46,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_18132\\2912694450.py:12: DtypeWarning: Columns (40,41,44,45,46,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_18132\\2912694450.py:12: DtypeWarning: Columns (40,41,44,45,46,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_18132\\2912694450.py:12: DtypeWarning: Columns (40,41,44,45,46,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_18132\\2912694450.py:12: DtypeWarning: Columns (40,41,44,45,46,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_18132\\2912694450.py:12: DtypeWarning: Columns (40,41,44,45,46,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price\n",
      "km\n",
      "year\n",
      "color\n",
      "cubicCapacity\n",
      "brand\n",
      "model\n",
      "version\n",
      "fuelType\n",
      "bodyTypeId\n",
      "transmissionTypeId\n",
      "doors\n",
      "seatingCapacity\n",
      "warranty_months\n",
      "province\n",
      "environmentalLabel\n",
      "co2Emissions\n",
      "co2EmissionsGramsPerKm\n",
      "trunkCapacityInLiters\n",
      "maxSpeed\n",
      "acceleration\n",
      "hasDetails\n",
      "jato_classification\n",
      "traction\n",
      "brakes\n",
      "front_suspension\n",
      "rear_suspension\n",
      "power_cv\n",
      "power_kw\n",
      "rpm_max_power\n",
      "max_torque_nm\n",
      "rpm_max_torque\n",
      "motor_description\n",
      "transmission_description\n",
      "speakers\n",
      "trip_computer\n",
      "remote_audio_control_on_steering_wheel\n",
      "dvd_navigation\n",
      "antenna\n",
      "abs\n",
      "electronic_traction_control\n",
      "parking_sensors\n",
      "airbag\n",
      "stability_control\n",
      "curve_braking_control\n",
      "isofix_system\n",
      "start_stop_automatic\n",
      "cubicCapacity_seat_folded\n",
      "Acabado Interior_Apoyabrazos\n",
      "Acabado Interior_Asiento\n",
      "Acabado Interior_Asientos\n",
      "Acabado Interior_Dos\n",
      "Acabado Interior_Pedales\n",
      "Acabado Interior_Reloj\n",
      "Acabado Interior_Reposacabezas\n",
      "Acabado Interior_Tres\n",
      "Acabado Interior_Uno\n",
      "Confort_Aire\n",
      "Confort_Apertura\n",
      "Confort_Aviso\n",
      "Confort_Banda\n",
      "Confort_Calefacción\n",
      "Confort_Cierre\n",
      "Confort_Compartimentos\n",
      "Confort_Control\n",
      "Confort_Dirección\n",
      "Confort_Dos\n",
      "Confort_Elevalunas\n",
      "Confort_Faros\n",
      "Confort_Indicador\n",
      "Confort_Inmovilizador\n",
      "Confort_Inmovilizador\n",
      "\n",
      "Confort_Intermitentes\n",
      "Confort_Lavafaros\n",
      "Confort_Lavafaros\n",
      "\n",
      "Confort_Limpiaparabrisas\n",
      "Confort_Llave\n",
      "Confort_Luces\n",
      "Confort_Luz\n",
      "Confort_Memoria\n",
      "Confort_Protección\n",
      "Confort_Regulación\n",
      "Confort_Sistema\n",
      "Confort_Tapa\n",
      "Confort_Tarjeta\n",
      "Confort_Techo\n",
      "Confort_Testigo\n",
      "Confort_Una\n",
      "Confort_Volante\n",
      "Acabado Exterior_Alerón\n",
      "Acabado Exterior_Cristales\n",
      "Acabado Exterior_Defensa\n",
      "Acabado Exterior_Faldones\n",
      "Acabado Exterior_Guardabarros\n",
      "Acabado Exterior_Llantas\n",
      "Acabado Exterior_Maletero\n",
      "Acabado Exterior_Molduras\n",
      "Acabado Exterior_Neumáticos\n",
      "Acabado Exterior_Pasos\n",
      "Acabado Exterior_Pintura\n",
      "Acabado Exterior_Puerta\n",
      "Acabado Exterior_Retrovisor\n",
      "Acabado Exterior_Rueda\n",
      "consumption.urban\n",
      "consumption.mixed\n",
      "consumption.extraUrban\n",
      "dimensions.width\n",
      "dimensions.height\n",
      "dimensions.length\n",
      "electricFeatures.powerSource.batteryType\n",
      "electricFeatures.powerSource.batteryVoltage.value\n",
      "electricFeatures.powerSource.batteryVoltage.unit\n",
      "electricFeatures.powerSource.maximumBatteryKWH.value\n",
      "electricFeatures.powerSource.maximumBatteryKWH.unit\n",
      "electricFeatures.power.maxPower.value\n",
      "electricFeatures.power.maxPower.unit\n",
      "electricFeatures.chargingInformation.standardMode.scenario\n",
      "electricFeatures.chargingInformation.standardMode.duration.value\n",
      "electricFeatures.chargingInformation.standardMode.duration.unit\n",
      "electricFeatures.chargingInformation.standardMode.amps.value\n",
      "electricFeatures.chargingInformation.standardMode.amps.unit\n",
      "electricFeatures.chargingInformation.fastMode.scenario\n",
      "electricFeatures.chargingInformation.fastMode.duration.value\n",
      "electricFeatures.chargingInformation.fastMode.duration.unit\n",
      "electricFeatures.chargingInformation.fastMode.maxKW.value\n",
      "electricFeatures.chargingInformation.fastMode.maxKW.unit\n",
      "electricFeatures.chargingInformation.fastMode.chargeEnd.value\n",
      "electricFeatures.chargingInformation.fastMode.chargeEnd.unit\n",
      "electricFeatures.motorType\n",
      "electricFeatures.chargingConnector\n",
      "electricFeatures.combinedConsumption.value\n",
      "electricFeatures.combinedConsumption.unit\n",
      "electricFeatures.combinedConsumption.testType\n",
      "electricFeatures.range.value\n",
      "electricFeatures.range.unit\n",
      "electricFeatures.powerSource.onboardCharger.value\n",
      "electricFeatures.powerSource.onboardCharger.unit\n",
      "electricFeatures.chargingInformation.standardMode.voltage.value\n",
      "electricFeatures.chargingInformation.standardMode.voltage.unit\n",
      "electricFeatures.chargingInformation.standardMode.chargeStart.value\n",
      "electricFeatures.chargingInformation.standardMode.chargeStart.unit\n",
      "electricFeatures.chargingInformation.standardMode.chargeEnd.value\n",
      "electricFeatures.chargingInformation.standardMode.chargeEnd.unit\n",
      "electricFeatures.chargingInformation.fastMode.chargeStart.value\n",
      "electricFeatures.chargingInformation.fastMode.chargeStart.unit\n",
      "electricFeatures.chargingInformation.fastMode.voltage.value\n",
      "electricFeatures.chargingInformation.fastMode.voltage.unit\n",
      "electricFeatures.chargingInformation.standardMode.maxKW.value\n",
      "electricFeatures.chargingInformation.standardMode.maxKW.unit\n",
      "electricFeatures.chargingInformation.fastMode.amps.value\n",
      "electricFeatures.chargingInformation.fastMode.amps.unit\n",
      "idx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def merge_csv_files_from_folder(folder_path):\n",
    "    # Lista para almacenar los DataFrames\n",
    "    df_list = []\n",
    "\n",
    "    # Recorrer todos los archivos en la carpeta\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.csv'):\n",
    "            # Obtener la ruta completa del archivo\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            \n",
    "            # Leer el archivo CSV y agregarlo a la lista de DataFrames\n",
    "            df = pd.read_csv(file_path)\n",
    "            df_list.append(df)\n",
    "\n",
    "    # Concatenar todos los DataFrames en uno solo\n",
    "    if df_list:\n",
    "        merged_df = pd.concat(df_list, ignore_index=True)\n",
    "        return merged_df\n",
    "    else:\n",
    "        print(\"No se encontraron archivos CSV en la carpeta.\")\n",
    "        return pd.DataFrame()  \n",
    "\n",
    "data = merge_csv_files_from_folder(\"data_processed/csv/\")\n",
    "data.drop(columns=\"car_id\", inplace=True)\n",
    "colnames = data.columns.to_list()\n",
    "for col in colnames: print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_18132\\2833469390.py:1: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0         NaN\n",
      "1         NaN\n",
      "2         NaN\n",
      "3         NaN\n",
      "4         NaN\n",
      "         ... \n",
      "165432    NaN\n",
      "165433    NaN\n",
      "165434    NaN\n",
      "165435    NaN\n",
      "165436    NaN\n",
      "Name: cubicCapacity_seat_folded, Length: 165437, dtype: object' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  for colum in [40,41,44,45,46,47]: data.iloc[:, colum] = data.iloc[:, colum].map({\"True\": True, \"False\": False})\n"
     ]
    }
   ],
   "source": [
    "for colum in [40,41,44,45,46,47]: data.iloc[:, colum] = data.iloc[:, colum].map({\"True\": True, \"False\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dirºty_columns(prefix): return [col for col in data.columns if prefix in col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Dirty Columns\n",
    "\n",
    "There are four columns that require cleaning: `^Confort_`, `^Acabado Interior_` (already cleaned), `^Acabado Exterior_`, and `^electricFeatures`. You need to select one of these columns and process the data until it becomes readable. All columns should carry meaningful information. If a column contains a wide range of phrases, you can merge them into a single column labeled as \"description,\" which will allow the application of NLP techniques later.\n",
    "\n",
    "### Guidelines for Cleaning:\n",
    "\n",
    "- **Singular and Plural Forms**:  \n",
    "  If two columns represent the same feature, but one is the plural form of the other (e.g., `Confort_Luz` and `Confort_Luces`), discard the plural column.\n",
    "\n",
    "- **Duplicate Column Names**:  \n",
    "  If two columns share the same name, you can discard one of them.\n",
    "\n",
    "- **Numbered Columns**:  \n",
    "  If multiple columns are part of a series ending with a number (e.g., `Confort_Dos`, `Confort_Uno`), they likely describe different aspects of a single feature. In this case, merge them into a single column.\n",
    "\n",
    "- **Relevance of Columns**:  \n",
    "  Most of the dirty columns have names that describe the feature of their information, but some columns may be irrelevant.\n",
    "\n",
    "- **Example for Reference**:  \n",
    "  The column `^Acabado Interior_` has already been cleaned and can serve as an example of how to approach the cleaning process.\n",
    "\n",
    "- **Nan and \"no tiene\"**:  \n",
    "  Some data has an Nan and \"no tiene\", the first one means that we don't know the data but probably you can deduce that feature with other columns, specially in electrical features, and the second the car does nor have that feature.\n",
    "\n",
    "**Data Types**:\n",
    "  BE CAREFULL most of the cells that contains \" ['Asiento de... \" is a string not a list\n",
    "  \n",
    "At the beginning of each section, you will find a printout of the columns that need to be cleaned.\n",
    "\n",
    "---\n",
    "\n",
    "Let me know if you need further revisions or clarification!\n",
    "\n",
    "\n",
    "## ~~Profe~~ **Lingfeng** te hacia `ilu` escribir esto no ? `XD` \n",
    "\n",
    "o espera\n",
    "\n",
    "Prof Lingfeng you enjoyed writing this, right? XD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(lista, elemento): return [x for x in lista if x != elemento]\n",
    "\n",
    "def check_unique_values(column):\n",
    "    ret = sorted(set(data[column].to_list()))\n",
    "    print(f\"Column: {column}\")\n",
    "    for x in ret: print(f'{x}: {data[column].to_list().count(x)}')\n",
    "    print(f'NA: {data[column].to_list().count(None)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Confort\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                  No tiene\n",
      "1               Sensores de aparcamiento traseros con radar\n",
      "2               Sensores de aparcamiento traseros con radar\n",
      "3         Sensores de aparcamiento delanteros con sensor...\n",
      "4              Sensores de aparcamiento traseros con sensor\n",
      "                                ...                        \n",
      "165432          Sensores de aparcamiento traseros con radar\n",
      "165433                                             No tiene\n",
      "165434    Sensores de aparcamiento traseros con radar y ...\n",
      "165435    Sensores de aparcamiento delanteros con sensor...\n",
      "165436                                             No tiene\n",
      "Name: parking_sensors, Length: 165437, dtype: object\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#for x in confort_columns: print(x)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparking_sensors\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m----> 4\u001b[0m \u001b[43mcheck_unique_values\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparking_sensors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m, in \u001b[0;36mcheck_unique_values\u001b[1;34m(column)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_unique_values\u001b[39m(column):\n\u001b[1;32m----> 4\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m ret: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata[column]\u001b[38;5;241m.\u001b[39mto_list()\u001b[38;5;241m.\u001b[39mcount(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "confort_columns = find_dirty_columns(\"Confort\")\n",
    "for x in confort_columns: print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_ac_zones(val):\n",
    "    cleaned_val = re.sub(r\"[\\[\\]']\", '', val).strip().lower()\n",
    "\n",
    "    match cleaned_val:\n",
    "        case val if 'bizona' in val:\n",
    "            return 'BIZONA'\n",
    "        case val if 'trizona' in val or '3 zonas' in val:\n",
    "            return 'TRIZONA'\n",
    "        case val if '4 zonas' in val:\n",
    "            return 'TETRAZONA'\n",
    "        case _:\n",
    "            return 'MONOZONA' \n",
    "        \n",
    "def classify_ac_type(val): \n",
    "    cleaned_val = re.sub(r\"[\\[\\]']\", '', val).strip().lower()\n",
    "    match cleaned_val:\n",
    "        case val if 'semi-auto' in val or 'semi-automático' in val or 'semi-automatico' in val:\n",
    "            return 'SEMIAUTO'\n",
    "        case val if 'automático' in val or 'auto' in val or 'automatico' in val:\n",
    "            return 'AUTO'\n",
    "        case val if 'manual' in val:\n",
    "            return 'MANUAL'\n",
    "        case val if 'no tiene' in val:\n",
    "            return 'NO_TIENE'\n",
    "        case _:\n",
    "            return 'STANDARD'  \n",
    "        \n",
    "def extraer_numero_tcinturones(text):\n",
    "    if 'un' in text: return 1\n",
    "    elif 'dos' in text:return 2\n",
    "    elif 'tres' in text:return 3\n",
    "    elif 'cuatro' in text:return 4\n",
    "    elif 'cinco' in text:return 5\n",
    "    elif 'seis' in text:return 6\n",
    "    elif 'siete' in text:return 7\n",
    "    elif 'Testigo' in text: return 2\n",
    "    else: return 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Barak\\AppData\\Local\\Temp\\ipykernel_17376\\1301228139.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"Techo_Deslizante\"] = data[\"Confort_Techo\"].map(lambda x:\n",
      "C:\\Users\\Barak\\AppData\\Local\\Temp\\ipykernel_17376\\1301228139.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"Control_Remoto\"] = data[\"Confort_Techo\"].map(lambda x:\n",
      "C:\\Users\\Barak\\AppData\\Local\\Temp\\ipykernel_17376\\1301228139.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"Testigo_Cinturones\"] = data[\"Confort_Testigo\"].map(lambda x:\n",
      "C:\\Users\\Barak\\AppData\\Local\\Temp\\ipykernel_17376\\1301228139.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"Numero_Testigos\"] = data[\"Confort_Testigo\"].map(extraer_numero_tcinturones)\n",
      "C:\\Users\\Barak\\AppData\\Local\\Temp\\ipykernel_17376\\1301228139.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"Confort_Volante_Descripción\"] = data[\"Confort_Volante\"]\n"
     ]
    }
   ],
   "source": [
    "#Confort Aire\n",
    "data[\"AC_Zones\"] = data[\"Confort_Aire\"].map(classify_ac_zones)\n",
    "data[\"AC_Type\"] = data[\"Confort_Aire\"].map(classify_ac_type) \n",
    "\n",
    "#Confort_Apertura\n",
    "#El maletero se abre a distancia? (Mecanicamente o electricamente)\n",
    "data[\"trunk_auto_open\"] = data[\"Confort_Apertura\"].map(lambda x: False if 'no tiene' in x else True)\n",
    "\n",
    "#Se podría quitar la verdad\n",
    "data[\"BandaTintada\"] = data[\"Confort_Banda\"].map(lambda x: False if 'no tiene' in x else True)\n",
    "\n",
    "data[\"Calefacción_Trasera\"] = data[\"Confort_Calefacción\"].map(lambda x: False if 'no tiene' in x else True)\n",
    "\n",
    "\n",
    "data['Doble_Cierre'] = data['Confort_Cierre'].map(lambda x: True if 'doble cierre' in x else False)\n",
    "data['Movil_NFC'] = data['Confort_Cierre'].map(lambda x: True if 'teléfono móvil' in x or 'NFC' in x else False)\n",
    "data['Metodo_Apertura'] = data['Confort_Cierre'].map(\n",
    "   lambda x: 'Mando a distancia' if 'mando a distancia' in x else\n",
    "              'Tarjeta/llave inteligente' if 'tarjeta/llave inteligente' in x else\n",
    "              'Llave' if 'llave' in x else\n",
    "              'Teléfono móvil' if 'teléfono móvil' in x else\n",
    "              'Desconocido'\n",
    ")\n",
    "\n",
    "\n",
    "data[\"Control_Crucero\"] = data[\"Confort_Control\"].map(lambda x: True if 'crucero' in x else False)\n",
    "data[\"Control_Crucero_Adaptativo\"] = data[\"Confort_Control\"].map(lambda x: True if 'adaptativo' in x else False)  \n",
    "data[\"SensoresDistancia\"] = data[\"Confort_Control\"].map(lambda x: True if 'distancia' in x else False)\n",
    "data[\"StopGo\"] = data[\"Confort_Control\"].map(lambda x: True if 'stop' in x else False)\n",
    "\n",
    "\n",
    "data[\"Dirección_Asistida\"] = data[\"Confort_Dirección\"].map(lambda x: True if 'dirección asistida' in x.lower() else False)\n",
    "data[\"Dirección_Electrica\"] = data[\"Confort_Dirección\"].map(lambda x: True if 'eléctrica' in x.lower() else False)\n",
    "data[\"Endurecimiento_Progresivo\"] = data[\"Confort_Dirección\"].map(lambda x: True if 'endurecimiento progresivo' in x.lower() else False)\n",
    "data[\"Desmultiplicacion_Variable\"] = data[\"Confort_Dirección\"].map(lambda x: True if 'desmultiplicación variable' in x.lower() else False)\n",
    "data[\"Dirección_Electro_Hidraulica\"] = data[\"Confort_Dirección\"].map(lambda x: True if 'electro-hidráulica' in x.lower() else False)\n",
    "\n",
    "\n",
    "data[\"Elevalunas_Electricos\"] = data[\"Confort_Elevalunas\"].map(lambda x: True if 'elevalunas eléctricos' in x.lower() else False)\n",
    "data[\"Un_Solo_Toque\"] = data[\"Confort_Elevalunas\"].map(lambda x: True if 'uno de ellos de un solo toque' in x.lower() or 'dos de ellos de un solo toque' in x.lower() else False)\n",
    "data[\"Elevalunas_Traseros\"] = data[\"Confort_Elevalunas\"].map(lambda x: True if 'traseros' in x.lower() else False)\n",
    "\n",
    "\n",
    "data[\"Tipo_Faro\"] = data[\"Confort_Faros\"].map(lambda x: \n",
    "    'LED' if 'led' in x.lower() else\n",
    "    'Xenón' if 'xenón' in x.lower() else\n",
    "    'Halógeno' if 'halógeno' in x.lower() else\n",
    "    'Otro')\n",
    "data[\"Luz_Larga\"] = data[\"Confort_Faros\"].map(lambda x: True if 'luz larga' in x.lower() else False)\n",
    "data[\"Faros_Dobles\"] = data[\"Confort_Faros\"].map(lambda x: True if 'dobles' in x.lower() else False)\n",
    "\n",
    "\n",
    "data[\"Indicador_Baja_Presion_Neumaticos\"] = data[\"Confort_Indicador\"].map(lambda x: \n",
    "    True if 'baja presion' in x.lower() else False)\n",
    "data[\"Visualizacion_Presion\"] = data[\"Confort_Indicador\"].map(lambda x: \n",
    "    True if 'visualización de presión' in x.lower() else False)\n",
    "data[\"Indicador_Consumo\"] = data[\"Confort_Indicador\"].map(lambda x: \n",
    "    True if 'indicador de consumo' in x.lower() else False)\n",
    "\n",
    "\n",
    "data[\"Inmovilizador\"] = data[\"Confort_Inmovilizador\"].map(lambda x: \n",
    "    True if 'Inmovilizador' in x else False)\n",
    "\n",
    "\n",
    "data[\"Intermitentes_Laterales\"] = data[\"Confort_Intermitentes\"].map(lambda x:\n",
    "    True if 'laterales' in x else False)\n",
    "\n",
    "\n",
    "data[\"Lavafaros\"] = data[\"Confort_Lavafaros\"].map(lambda x:\n",
    "    True if 'Lavafaros' in x else False)\n",
    "\n",
    "\n",
    "data[\"Sensor_Lluvia\"] = data[\"Confort_Limpiaparabrisas\"].map(lambda x: \n",
    "    True if 'sensor de lluvia' in x.lower() else False)\n",
    "data[\"Intermitencia_Automatica\"] = data[\"Confort_Limpiaparabrisas\"].map(lambda x: \n",
    "    True if 'intermitencia automática' in x.lower() else False)\n",
    "\n",
    "\n",
    "data[\"Luces_Lectura\"] = data[\"Confort_Luces\"].map(lambda x: \n",
    "    True if 'luces de lectura' in x.lower() else False)\n",
    "data[\"Luces_Antiniebla\"] = data[\"Confort_Luces\"].map(lambda x: \n",
    "    True if 'luces antiniebla' in x.lower() else False)\n",
    "data[\"Luces_Cortesía\"] = data[\"Confort_Luces\"].map(lambda x: \n",
    "    True if 'luces de cortesía' in x.lower() else False)\n",
    "data[\"Luces_Laterales\"] = data[\"Confort_Luces\"].map(lambda x: \n",
    "    True if 'luces laterales maniobras' in x.lower() else False)\n",
    "\n",
    "\n",
    "data[\"Memoria_Asientos\"] = data[\"Confort_Memoria\"].map(lambda x: \n",
    "    True if 'posición' in x else False)\n",
    "\n",
    "\n",
    "data[\"Techo_Electrico\"] = data[\"Confort_Techo\"].map(lambda x: \n",
    "    True if 'eléctrico' in x.lower() else False)\n",
    "data[\"Techo_Inclinable\"] = data[\"Confort_Techo\"].map(lambda x: \n",
    "    True if 'inclinable' in x.lower() else False)\n",
    "data[\"Techo_Deslizante\"] = data[\"Confort_Techo\"].map(lambda x: \n",
    "    True if 'deslizante' in x.lower() else False)\n",
    "data[\"Control_Remoto\"] = data[\"Confort_Techo\"].map(lambda x: \n",
    "    True if 'control remoto' in x.lower() else False)\n",
    "\n",
    "data[\"Testigo_Cinturones\"] = data[\"Confort_Testigo\"].map(lambda x: \n",
    "    True if 'testigo de cinturones' in x.lower() else False)\n",
    "\n",
    "data[\"Numero_Testigos\"] = data[\"Confort_Testigo\"].map(extraer_numero_tcinturones)\n",
    "\n",
    "\n",
    "# Feed para el modelo NLP\n",
    "data[\"Confort_Volante_Descripción\"] = data[\"Confort_Volante\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminar todas las columas con descripciones iniciales\n",
    "for col in confort_columns: \n",
    "    data.drop(columns=col, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Acabado Interior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "acabado_interior_columns = find_dirty_columns(\"Acabado Interior\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "acabado_interior_columns.remove(\"Acabado Interior_Asientos\")\n",
    "data.drop(columns=\"Acabado Interior_Asientos\", inplace=True)\n",
    "\n",
    "#for x in acabado_interior_columns: print(x)\n",
    "#data[acabado_interior_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Barak\\AppData\\Local\\Temp\\ipykernel_17376\\3934963263.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"sports_pedals\"] = data[\"Acabado Interior_Pedales\"].map({\n",
      "C:\\Users\\Barak\\AppData\\Local\\Temp\\ipykernel_17376\\3934963263.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"interior_clock\"] = data[\"Acabado Interior_Reloj\"].map({\n"
     ]
    }
   ],
   "source": [
    "data[\"sports_pedals\"] = data[\"Acabado Interior_Pedales\"].map({\n",
    "    \"['Pedales deportivos']\": True, \n",
    "    'no tiene': False\n",
    "})\n",
    "data[\"interior_clock\"] = data[\"Acabado Interior_Reloj\"].map({\n",
    "    \"['Reloj analógico']\": 'analogico', \n",
    "    \"['Reloj digital']\": 'digital',\n",
    "    \"['Reloj']\": 'regular',\n",
    "    \"no tiene\": 'no tiene'\n",
    "})\n",
    "\n",
    "#check_unique_values(\"sports_pedals\")\n",
    "#check_unique_values(\"interior_clock\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Barak\\AppData\\Local\\Temp\\ipykernel_17376\\2034675041.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"arm_suppport_front\"] = data[\"Acabado Interior_Apoyabrazos\"].map(lambda x: x if x == 'no tiene' else process_arm_suppport_front(eval(x)) )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: arm_suppport_front\n",
      "Tiene: 117241\n",
      "abatible: 98\n",
      "ajustable: 1\n",
      "caja integrada: 4238\n",
      "no tiene: 43859\n",
      "NA: 0\n",
      "Column: arm_suppport_back\n",
      "Tiene: 64993\n",
      "abatible: 5\n",
      "acceso maletero: 406\n",
      "ajustable: 2\n",
      "caja integrada: 1415\n",
      "caja integrada acceso maletero: 559\n",
      "no tiene: 98057\n",
      "NA: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Barak\\AppData\\Local\\Temp\\ipykernel_17376\\2034675041.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"arm_suppport_back\"] = data[\"Acabado Interior_Apoyabrazos\"].map(lambda x: x if x == 'no tiene' else process_arm_suppport_back(eval(x)) )\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def process_arm_suppport_front(phrases: list) -> str:\n",
    "    stop_words = set(stopwords.words('spanish'))\n",
    "    stop_words.add(\",\")\n",
    "    text = \" # \".join(phrases)\n",
    "    if not ('delantero' in text): return (\"no tiene\")\n",
    "    text = [word for word in text.split() if word not in stop_words]\n",
    "    if '#' in text: \n",
    "        ret = \" \".join( text[ (text.index('delantero')+1):text.index('#')] )\n",
    "        return \"Tiene\" if len(ret) == 0 else ret\n",
    "    else: \n",
    "        ret = \" \".join( text[(text.index('delantero')+1):len(text)] ) \n",
    "        return \"Tiene\" if len(ret) == 0 else ret\n",
    "\n",
    "def process_arm_suppport_back(phrases: list) -> str:\n",
    "    stop_words = set(stopwords.words('spanish'))\n",
    "    stop_words.add(\",\")\n",
    "    text = \" # \".join(phrases)\n",
    "    if not ('trasero' in text): return (\"no tiene\")\n",
    "\n",
    "    text = [word for word in text.split() if word not in stop_words]\n",
    "\n",
    "    ret = \" \".join( text[(text.index('trasero')+1):len(text)] ) \n",
    "    return \"Tiene\" if len(ret) == 0 else ret \n",
    "\n",
    "data[\"arm_suppport_front\"] = data[\"Acabado Interior_Apoyabrazos\"].map(lambda x: x if x == 'no tiene' else process_arm_suppport_front(eval(x)) )\n",
    "data[\"arm_suppport_back\"] = data[\"Acabado Interior_Apoyabrazos\"].map(lambda x: x if x == 'no tiene' else process_arm_suppport_back(eval(x)) )\n",
    "\n",
    "check_unique_values(\"arm_suppport_front\")\n",
    "check_unique_values(\"arm_suppport_back\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Barak\\AppData\\Local\\Temp\\ipykernel_17376\\3282028378.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"seat_description\"] = data[\"Acabado Interior_Asiento\"].map( lambda x: x if x == 'no tiene' else process_seat_description(eval(x)) )\n"
     ]
    }
   ],
   "source": [
    "def process_seat_description(phrases: list) -> str: return \". \".join(phrases)\n",
    "\n",
    "data[\"seat_description\"] = data[\"Acabado Interior_Asiento\"].map( lambda x: x if x == 'no tiene' else process_seat_description(eval(x)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Acabado Interior_Uno\"] = data[\"Acabado Interior_Uno\"].map( lambda x: \"['no tiene']\" if x == 'no tiene' else x )\n",
    "data[\"Acabado Interior_Dos\"] = data[\"Acabado Interior_Dos\"].map( lambda x: \"['no tiene']\" if x == 'no tiene' else x )\n",
    "data[\"Acabado Interior_Tres\"] = data[\"Acabado Interior_Tres\"].map( lambda x: \"['no tiene']\" if x == 'no tiene' else x )\n",
    "data[\"Acabado Interior_Reposacabezas\"] = data[\"Acabado Interior_Reposacabezas\"].map( lambda x: \"['no tiene']\" if x == 'no tiene' else x )\n",
    "\n",
    "data[\"Acabado Interior_Uno\"] = data[\"Acabado Interior_Uno\"].map(ast.literal_eval)\n",
    "data[\"Acabado Interior_Dos\"] = data[\"Acabado Interior_Dos\"].map(ast.literal_eval)\n",
    "data[\"Acabado Interior_Tres\"] = data[\"Acabado Interior_Tres\"].map(ast.literal_eval)\n",
    "data[\"Acabado Interior_Reposacabezas\"] = data[\"Acabado Interior_Reposacabezas\"].map(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Barak\\AppData\\Local\\Temp\\ipykernel_17376\\550879491.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['head_supporter'] = data.apply(\n"
     ]
    }
   ],
   "source": [
    "data['head_supporter'] = data.apply(\n",
    "    lambda row: \". \".join(\n",
    "        remove_duplicates(row[\"Acabado Interior_Uno\"] + row[\"Acabado Interior_Dos\"] + row[\"Acabado Interior_Tres\"] + row[\"Acabado Interior_Reposacabezas\"], 'no tiene')\n",
    "    ), \n",
    "    axis=1)\n",
    "#check_unique_values(\"head_supporter\")\n",
    "\n",
    "for col in acabado_interior_columns: data.drop(columns= col, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Acabado Exterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopw = frozenset(stopwords.words('spanish')) | {\",\"}\n",
    "\n",
    "def cleanTry(phrases: list) -> str:\n",
    "    if not phrases:\n",
    "        return \"no tiene\"\n",
    "    \n",
    "    # Join phrases into a single string and clean punctuation\n",
    "    text = \" \".join(phrases)\n",
    "    \n",
    "    # Remove stopwords efficiently\n",
    "    text = [word for word in text.split() if word.lower() not in stopw]\n",
    "\n",
    "    # Return cleaned text or \"no tiene\" if empty\n",
    "    return \"no tiene\" if len(text) == 0 else \" \".join(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=[\"Acabado Exterior_Maletero\",\"Acabado Exterior_Pasos\",\"Acabado Exterior_Maletero\",\"Acabado Exterior_Defensa\",\"Acabado Exterior_Guardabarros\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18132\\696600981.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0macabado_exterior_columns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_dirty_columns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Acabado Exterior\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpatata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0macabado_exterior_columns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcleanTry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'no tiene'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0macabado_exterior_columns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\marti\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m  10370\u001b[0m             \u001b[0mengine_kwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine_kwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10371\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10372\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10373\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10374\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"apply\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\marti\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    912\u001b[0m         \u001b[1;31m# raw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine_kwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 916\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\marti\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1063\u001b[1;33m             \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1064\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1065\u001b[0m             \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_series_numba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1066\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\marti\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1077\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1078\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"mode.chained_assignment\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1079\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m                 \u001b[1;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1081\u001b[1;33m                 \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m                     \u001b[1;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m                     \u001b[1;31m#  series_generator will swap out the underlying data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18132\\696600981.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(x)\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpatata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0macabado_exterior_columns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcleanTry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'no tiene'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\marti\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1575\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1576\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1577\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m   1578\u001b[0m             \u001b[1;33mf\"\u001b[0m\u001b[1;33mThe truth value of a \u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m is ambiguous. \u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1579\u001b[0m             \u001b[1;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1580\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "acabado_exterior_columns = find_dirty_columns(\"Acabado Exterior\")\n",
    "patata = data[acabado_exterior_columns].apply(lambda x: cleanTry(eval(x)) if x != 'no tiene' else x)\n",
    "for x in acabado_exterior_columns: \n",
    "    print(patata[x].value_counts())\n",
    "    print(x)\n",
    "    print(\"Descripcion --------------------------\")\n",
    "    print(data[x].describe())\n",
    "    print(\"Counts--------------------------------\")\n",
    "    print(data[x].value_counts())\n",
    "    print(\"CleanTry------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Electronic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                   Gasolina\n",
      "1                   Gasolina\n",
      "2                   Gasolina\n",
      "3                  Eléctrico\n",
      "4                    Híbrido\n",
      "                 ...        \n",
      "165432                Diésel\n",
      "165433              Gasolina\n",
      "165434               Híbrido\n",
      "165435    Híbrido enchufable\n",
      "165436              Gasolina\n",
      "Name: fuelType, Length: 165437, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data[\"fuelType\"])\n",
    "#check_unique_values(\"fuelType\") Pone que hay un float en esa columna, solucionalo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m start_row \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(df):\n\u001b[0;32m     21\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m split_dataframe_to_csv(\u001b[43mdata\u001b[49m, max_file_size, base_filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m check_unique_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparking_sensors\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "max_file_size = 100 * 1024 * 1024\n",
    "output_folder = \"NLP/test_data\"\n",
    "def split_dataframe_to_csv(df, max_file_size, base_filename):\n",
    "    file_index = 1\n",
    "    chunk_size = len(df) // 7 \n",
    "    while chunk_size > 0:\n",
    "        start_row = 0\n",
    "        while start_row < len(df):\n",
    "            end_row = start_row + chunk_size\n",
    "            chunk = df.iloc[start_row:end_row]\n",
    "            filename = f\"{output_folder}/{base_filename}_part{file_index}.csv\"\n",
    "            chunk.to_csv(filename, index=False)\n",
    "            if os.path.getsize(filename) > max_file_size:\n",
    "                chunk_size //= 2\n",
    "                os.remove(filename)\n",
    "            else:\n",
    "                start_row = end_row\n",
    "                file_index += 1\n",
    "\n",
    "        if start_row >= len(df):\n",
    "            break\n",
    "\n",
    "split_dataframe_to_csv(data, max_file_size, base_filename=\"test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
