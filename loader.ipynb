{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "We import some neccesary libraries and download some global scope data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lingf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import ast\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Datsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lingf\\AppData\\Local\\Temp\\ipykernel_17108\\2912694450.py:12: DtypeWarning: Columns (40,41,44,45,46,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\lingf\\AppData\\Local\\Temp\\ipykernel_17108\\2912694450.py:12: DtypeWarning: Columns (40,41,44,45,46,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\lingf\\AppData\\Local\\Temp\\ipykernel_17108\\2912694450.py:12: DtypeWarning: Columns (40,41,44,45,46,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\lingf\\AppData\\Local\\Temp\\ipykernel_17108\\2912694450.py:12: DtypeWarning: Columns (40,41,44,45,46,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\lingf\\AppData\\Local\\Temp\\ipykernel_17108\\2912694450.py:12: DtypeWarning: Columns (40,41,44,45,46,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\lingf\\AppData\\Local\\Temp\\ipykernel_17108\\2912694450.py:12: DtypeWarning: Columns (40,41,44,45,46,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Users\\lingf\\AppData\\Local\\Temp\\ipykernel_17108\\2912694450.py:12: DtypeWarning: Columns (40,41,44,45,46,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price\n",
      "km\n",
      "year\n",
      "color\n",
      "cubicCapacity\n",
      "brand\n",
      "model\n",
      "version\n",
      "fuelType\n",
      "bodyTypeId\n",
      "transmissionTypeId\n",
      "doors\n",
      "seatingCapacity\n",
      "warranty_months\n",
      "province\n",
      "environmentalLabel\n",
      "co2Emissions\n",
      "co2EmissionsGramsPerKm\n",
      "trunkCapacityInLiters\n",
      "maxSpeed\n",
      "acceleration\n",
      "hasDetails\n",
      "jato_classification\n",
      "traction\n",
      "brakes\n",
      "front_suspension\n",
      "rear_suspension\n",
      "power_cv\n",
      "power_kw\n",
      "rpm_max_power\n",
      "max_torque_nm\n",
      "rpm_max_torque\n",
      "motor_description\n",
      "transmission_description\n",
      "speakers\n",
      "trip_computer\n",
      "remote_audio_control_on_steering_wheel\n",
      "dvd_navigation\n",
      "antenna\n",
      "abs\n",
      "electronic_traction_control\n",
      "parking_sensors\n",
      "airbag\n",
      "stability_control\n",
      "curve_braking_control\n",
      "isofix_system\n",
      "start_stop_automatic\n",
      "cubicCapacity_seat_folded\n",
      "Acabado Interior_Apoyabrazos\n",
      "Acabado Interior_Asiento\n",
      "Acabado Interior_Asientos\n",
      "Acabado Interior_Dos\n",
      "Acabado Interior_Pedales\n",
      "Acabado Interior_Reloj\n",
      "Acabado Interior_Reposacabezas\n",
      "Acabado Interior_Tres\n",
      "Acabado Interior_Uno\n",
      "Confort_Aire\n",
      "Confort_Apertura\n",
      "Confort_Aviso\n",
      "Confort_Banda\n",
      "Confort_Calefacción\n",
      "Confort_Cierre\n",
      "Confort_Compartimentos\n",
      "Confort_Control\n",
      "Confort_Dirección\n",
      "Confort_Dos\n",
      "Confort_Elevalunas\n",
      "Confort_Faros\n",
      "Confort_Indicador\n",
      "Confort_Inmovilizador\n",
      "Confort_Inmovilizador\n",
      "\n",
      "Confort_Intermitentes\n",
      "Confort_Lavafaros\n",
      "Confort_Lavafaros\n",
      "\n",
      "Confort_Limpiaparabrisas\n",
      "Confort_Llave\n",
      "Confort_Luces\n",
      "Confort_Luz\n",
      "Confort_Memoria\n",
      "Confort_Protección\n",
      "Confort_Regulación\n",
      "Confort_Sistema\n",
      "Confort_Tapa\n",
      "Confort_Tarjeta\n",
      "Confort_Techo\n",
      "Confort_Testigo\n",
      "Confort_Una\n",
      "Confort_Volante\n",
      "Acabado Exterior_Alerón\n",
      "Acabado Exterior_Cristales\n",
      "Acabado Exterior_Defensa\n",
      "Acabado Exterior_Faldones\n",
      "Acabado Exterior_Guardabarros\n",
      "Acabado Exterior_Llantas\n",
      "Acabado Exterior_Maletero\n",
      "Acabado Exterior_Molduras\n",
      "Acabado Exterior_Neumáticos\n",
      "Acabado Exterior_Pasos\n",
      "Acabado Exterior_Pintura\n",
      "Acabado Exterior_Puerta\n",
      "Acabado Exterior_Retrovisor\n",
      "Acabado Exterior_Rueda\n",
      "consumption.urban\n",
      "consumption.mixed\n",
      "consumption.extraUrban\n",
      "dimensions.width\n",
      "dimensions.height\n",
      "dimensions.length\n",
      "electricFeatures.powerSource.batteryType\n",
      "electricFeatures.powerSource.batteryVoltage.value\n",
      "electricFeatures.powerSource.batteryVoltage.unit\n",
      "electricFeatures.powerSource.maximumBatteryKWH.value\n",
      "electricFeatures.powerSource.maximumBatteryKWH.unit\n",
      "electricFeatures.power.maxPower.value\n",
      "electricFeatures.power.maxPower.unit\n",
      "electricFeatures.chargingInformation.standardMode.scenario\n",
      "electricFeatures.chargingInformation.standardMode.duration.value\n",
      "electricFeatures.chargingInformation.standardMode.duration.unit\n",
      "electricFeatures.chargingInformation.standardMode.amps.value\n",
      "electricFeatures.chargingInformation.standardMode.amps.unit\n",
      "electricFeatures.chargingInformation.fastMode.scenario\n",
      "electricFeatures.chargingInformation.fastMode.duration.value\n",
      "electricFeatures.chargingInformation.fastMode.duration.unit\n",
      "electricFeatures.chargingInformation.fastMode.maxKW.value\n",
      "electricFeatures.chargingInformation.fastMode.maxKW.unit\n",
      "electricFeatures.chargingInformation.fastMode.chargeEnd.value\n",
      "electricFeatures.chargingInformation.fastMode.chargeEnd.unit\n",
      "electricFeatures.motorType\n",
      "electricFeatures.chargingConnector\n",
      "electricFeatures.combinedConsumption.value\n",
      "electricFeatures.combinedConsumption.unit\n",
      "electricFeatures.combinedConsumption.testType\n",
      "electricFeatures.range.value\n",
      "electricFeatures.range.unit\n",
      "electricFeatures.powerSource.onboardCharger.value\n",
      "electricFeatures.powerSource.onboardCharger.unit\n",
      "electricFeatures.chargingInformation.standardMode.voltage.value\n",
      "electricFeatures.chargingInformation.standardMode.voltage.unit\n",
      "electricFeatures.chargingInformation.standardMode.chargeStart.value\n",
      "electricFeatures.chargingInformation.standardMode.chargeStart.unit\n",
      "electricFeatures.chargingInformation.standardMode.chargeEnd.value\n",
      "electricFeatures.chargingInformation.standardMode.chargeEnd.unit\n",
      "electricFeatures.chargingInformation.fastMode.chargeStart.value\n",
      "electricFeatures.chargingInformation.fastMode.chargeStart.unit\n",
      "electricFeatures.chargingInformation.fastMode.voltage.value\n",
      "electricFeatures.chargingInformation.fastMode.voltage.unit\n",
      "electricFeatures.chargingInformation.standardMode.maxKW.value\n",
      "electricFeatures.chargingInformation.standardMode.maxKW.unit\n",
      "electricFeatures.chargingInformation.fastMode.amps.value\n",
      "electricFeatures.chargingInformation.fastMode.amps.unit\n",
      "idx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def merge_csv_files_from_folder(folder_path):\n",
    "    # Lista para almacenar los DataFrames\n",
    "    df_list = []\n",
    "\n",
    "    # Recorrer todos los archivos en la carpeta\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.csv'):\n",
    "            # Obtener la ruta completa del archivo\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            \n",
    "            # Leer el archivo CSV y agregarlo a la lista de DataFrames\n",
    "            df = pd.read_csv(file_path)\n",
    "            df_list.append(df)\n",
    "\n",
    "    # Concatenar todos los DataFrames en uno solo\n",
    "    if df_list:\n",
    "        merged_df = pd.concat(df_list, ignore_index=True)\n",
    "        return merged_df\n",
    "    else:\n",
    "        print(\"No se encontraron archivos CSV en la carpeta.\")\n",
    "        return pd.DataFrame()  \n",
    "\n",
    "data = merge_csv_files_from_folder(\"data_processed/csv/\")\n",
    "data.drop(columns=\"car_id\", inplace=True)\n",
    "colnames = data.columns.to_list()\n",
    "for col in colnames: print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_boolean(value):\n",
    "    if value == \"True\":\n",
    "        return True\n",
    "    elif value == \"False\":\n",
    "        return False\n",
    "    else:\n",
    "        return value\n",
    "for colum in [40,41,44,45,46,47]: data.iloc[:, colum] = data.iloc[:, colum].apply(lambda x: convert_boolean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dirty_columns(prefix): return [col for col in data.columns if prefix in col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Dirty Columns\n",
    "\n",
    "There are four columns that require cleaning: `^Confort_`, `^Acabado Interior_` (already cleaned), `^Acabado Exterior_`, and `^electricFeatures`. You need to select one of these columns and process the data until it becomes readable. All columns should carry meaningful information. If a column contains a wide range of phrases, you can merge them into a single column labeled as \"description,\" which will allow the application of NLP techniques later.\n",
    "\n",
    "### Guidelines for Cleaning:\n",
    "\n",
    "- **Singular and Plural Forms**:  \n",
    "  If two columns represent the same feature, but one is the plural form of the other (e.g., `Confort_Luz` and `Confort_Luces`), discard the plural column.\n",
    "\n",
    "- **Duplicate Column Names**:  \n",
    "  If two columns share the same name, you can discard one of them.\n",
    "\n",
    "- **Numbered Columns**:  \n",
    "  If multiple columns are part of a series ending with a number (e.g., `Confort_Dos`, `Confort_Uno`), they likely describe different aspects of a single feature. In this case, merge them into a single column.\n",
    "\n",
    "- **Relevance of Columns**:  \n",
    "  Most of the dirty columns have names that describe the feature of their information, but some columns may be irrelevant.\n",
    "\n",
    "- **Example for Reference**:  \n",
    "  The column `^Acabado Interior_` has already been cleaned and can serve as an example of how to approach the cleaning process.\n",
    "\n",
    "- **Nan and \"no tiene\"**:  \n",
    "  Some data has an Nan and \"no tiene\", the first one means that we don't know the data but probably you can deduce that feature with other columns, specially in electrical features, and the second the car does nor have that feature.\n",
    "\n",
    "**Data Types**:\n",
    "  BE CAREFULL most of the cells that contains \" ['Asiento de... \" is a string not a list\n",
    "  \n",
    "At the beginning of each section, you will find a printout of the columns that need to be cleaned.\n",
    "\n",
    "---\n",
    "\n",
    "Let me know if you need further revisions or clarification!\n",
    "\n",
    "\n",
    "## ~~Profe~~ **Lingfeng** te hacia `ilu` escribir esto no ? `XD` \n",
    "\n",
    "o espera\n",
    "\n",
    "Prof Lingfeng you enjoyed writing this, right? XD \n",
    "\n",
    "of course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(lista, elemento): return [x for x in lista if x != elemento]\n",
    "\n",
    "def check_unique_values(column):\n",
    "    ret = sorted(set(data[column].to_list()))\n",
    "    print(f\"Column: {column}\")\n",
    "    for x in ret: print(f'{x}: {data[column].to_list().count(x)}')\n",
    "    print(f'NA: {data[column].to_list().count(None)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Confort\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confort_Aire\n",
      "Confort_Apertura\n",
      "Confort_Aviso\n",
      "Confort_Banda\n",
      "Confort_Calefacción\n",
      "Confort_Cierre\n",
      "Confort_Compartimentos\n",
      "Confort_Control\n",
      "Confort_Dirección\n",
      "Confort_Dos\n",
      "Confort_Elevalunas\n",
      "Confort_Faros\n",
      "Confort_Indicador\n",
      "Confort_Inmovilizador\n",
      "Confort_Inmovilizador\n",
      "\n",
      "Confort_Intermitentes\n",
      "Confort_Lavafaros\n",
      "Confort_Lavafaros\n",
      "\n",
      "Confort_Limpiaparabrisas\n",
      "Confort_Llave\n",
      "Confort_Luces\n",
      "Confort_Luz\n",
      "Confort_Memoria\n",
      "Confort_Protección\n",
      "Confort_Regulación\n",
      "Confort_Sistema\n",
      "Confort_Tapa\n",
      "Confort_Tarjeta\n",
      "Confort_Techo\n",
      "Confort_Testigo\n",
      "Confort_Una\n",
      "Confort_Volante\n"
     ]
    }
   ],
   "source": [
    "confort_columns = find_dirty_columns(\"Confort\")\n",
    "for x in confort_columns: print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_ac_zones(val):\n",
    "    cleaned_val = re.sub(r\"[\\[\\]']\", '', val).strip().lower()\n",
    "\n",
    "    match cleaned_val:\n",
    "        case val if 'bizona' in val:\n",
    "            return 'BIZONA'\n",
    "        case val if 'trizona' in val or '3 zonas' in val:\n",
    "            return 'TRIZONA'\n",
    "        case val if '4 zonas' in val:\n",
    "            return 'TETRAZONA'\n",
    "        case _:\n",
    "            return 'MONOZONA' \n",
    "        \n",
    "def classify_ac_type(val): \n",
    "    cleaned_val = re.sub(r\"[\\[\\]']\", '', val).strip().lower()\n",
    "    match cleaned_val:\n",
    "        case val if 'semi-auto' in val or 'semi-automático' in val or 'semi-automatico' in val:\n",
    "            return 'SEMIAUTO'\n",
    "        case val if 'automático' in val or 'auto' in val or 'automatico' in val:\n",
    "            return 'AUTO'\n",
    "        case val if 'manual' in val:\n",
    "            return 'MANUAL'\n",
    "        case val if 'no tiene' in val:\n",
    "            return 'NO_TIENE'\n",
    "        case _:\n",
    "            return 'STANDARD'  \n",
    "        \n",
    "def extraer_numero_tcinturones(text):\n",
    "    if 'un' in text: return 1\n",
    "    elif 'dos' in text:return 2\n",
    "    elif 'tres' in text:return 3\n",
    "    elif 'cuatro' in text:return 4\n",
    "    elif 'cinco' in text:return 5\n",
    "    elif 'seis' in text:return 6\n",
    "    elif 'siete' in text:return 7\n",
    "    elif 'Testigo' in text: return 2\n",
    "    else: return 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lingf\\AppData\\Local\\Temp\\ipykernel_17108\\2351505979.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"Techo_Deslizante\"] = data[\"Confort_Techo\"].apply(lambda x:\n",
      "C:\\Users\\lingf\\AppData\\Local\\Temp\\ipykernel_17108\\2351505979.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"Control_Remoto\"] = data[\"Confort_Techo\"].apply(lambda x:\n",
      "C:\\Users\\lingf\\AppData\\Local\\Temp\\ipykernel_17108\\2351505979.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"Testigo_Cinturones\"] = data[\"Confort_Testigo\"].apply(lambda x:\n",
      "C:\\Users\\lingf\\AppData\\Local\\Temp\\ipykernel_17108\\2351505979.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"Numero_Testigos\"] = data[\"Confort_Testigo\"].apply(extraer_numero_tcinturones)\n",
      "C:\\Users\\lingf\\AppData\\Local\\Temp\\ipykernel_17108\\2351505979.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"Confort_Volante_Descripción\"] = data[\"Confort_Volante\"]\n"
     ]
    }
   ],
   "source": [
    "#Confort Aire\n",
    "data[\"AC_Zones\"] = data[\"Confort_Aire\"].apply(classify_ac_zones)\n",
    "data[\"AC_Type\"] = data[\"Confort_Aire\"].apply(classify_ac_type) \n",
    "\n",
    "#Confort_Apertura\n",
    "#El maletero se abre a distancia? (Mecanicamente o electricamente)\n",
    "data[\"trunk_auto_open\"] = data[\"Confort_Apertura\"].apply(lambda x: False if 'no tiene' in x else True)\n",
    "\n",
    "#Se podría quitar la verdad\n",
    "data[\"BandaTintada\"] = data[\"Confort_Banda\"].apply(lambda x: False if 'no tiene' in x else True)\n",
    "\n",
    "data[\"Calefacción_Trasera\"] = data[\"Confort_Calefacción\"].apply(lambda x: False if 'no tiene' in x else True)\n",
    "\n",
    "\n",
    "data['Doble_Cierre'] = data['Confort_Cierre'].apply(lambda x: True if 'doble cierre' in x else False)\n",
    "data['Movil_NFC'] = data['Confort_Cierre'].apply(lambda x: True if 'teléfono móvil' in x or 'NFC' in x else False)\n",
    "data['Metodo_Apertura'] = data['Confort_Cierre'].apply(\n",
    "   lambda x: 'Mando a distancia' if 'mando a distancia' in x else\n",
    "              'Tarjeta/llave inteligente' if 'tarjeta/llave inteligente' in x else\n",
    "              'Llave' if 'llave' in x else\n",
    "              'Teléfono móvil' if 'teléfono móvil' in x else\n",
    "              'Desconocido'\n",
    ")\n",
    "\n",
    "\n",
    "data[\"Control_Crucero\"] = data[\"Confort_Control\"].apply(lambda x: True if 'crucero' in x else False)\n",
    "data[\"Control_Crucero_Adaptativo\"] = data[\"Confort_Control\"].apply(lambda x: True if 'adaptativo' in x else False)  \n",
    "data[\"SensoresDistancia\"] = data[\"Confort_Control\"].apply(lambda x: True if 'distancia' in x else False)\n",
    "data[\"StopGo\"] = data[\"Confort_Control\"].apply(lambda x: True if 'stop' in x else False)\n",
    "\n",
    "\n",
    "data[\"Dirección_Asistida\"] = data[\"Confort_Dirección\"].apply(lambda x: True if 'dirección asistida' in x.lower() else False)\n",
    "data[\"Dirección_Electrica\"] = data[\"Confort_Dirección\"].apply(lambda x: True if 'eléctrica' in x.lower() else False)\n",
    "data[\"Endurecimiento_Progresivo\"] = data[\"Confort_Dirección\"].apply(lambda x: True if 'endurecimiento progresivo' in x.lower() else False)\n",
    "data[\"Desmultiplicacion_Variable\"] = data[\"Confort_Dirección\"].apply(lambda x: True if 'desmultiplicación variable' in x.lower() else False)\n",
    "data[\"Dirección_Electro_Hidraulica\"] = data[\"Confort_Dirección\"].apply(lambda x: True if 'electro-hidráulica' in x.lower() else False)\n",
    "\n",
    "\n",
    "data[\"Elevalunas_Electricos\"] = data[\"Confort_Elevalunas\"].apply(lambda x: True if 'elevalunas eléctricos' in x.lower() else False)\n",
    "data[\"Un_Solo_Toque\"] = data[\"Confort_Elevalunas\"].apply(lambda x: True if 'uno de ellos de un solo toque' in x.lower() or 'dos de ellos de un solo toque' in x.lower() else False)\n",
    "data[\"Elevalunas_Traseros\"] = data[\"Confort_Elevalunas\"].apply(lambda x: True if 'traseros' in x.lower() else False)\n",
    "\n",
    "\n",
    "data[\"Tipo_Faro\"] = data[\"Confort_Faros\"].apply(lambda x: \n",
    "    'LED' if 'led' in x.lower() else\n",
    "    'Xenón' if 'xenón' in x.lower() else\n",
    "    'Halógeno' if 'halógeno' in x.lower() else\n",
    "    'Otro')\n",
    "data[\"Luz_Larga\"] = data[\"Confort_Faros\"].apply(lambda x: True if 'luz larga' in x.lower() else False)\n",
    "data[\"Faros_Dobles\"] = data[\"Confort_Faros\"].apply(lambda x: True if 'dobles' in x.lower() else False)\n",
    "\n",
    "\n",
    "data[\"Indicador_Baja_Presion_Neumaticos\"] = data[\"Confort_Indicador\"].apply(lambda x: \n",
    "    True if 'baja presion' in x.lower() else False)\n",
    "data[\"Visualizacion_Presion\"] = data[\"Confort_Indicador\"].apply(lambda x: \n",
    "    True if 'visualización de presión' in x.lower() else False)\n",
    "data[\"Indicador_Consumo\"] = data[\"Confort_Indicador\"].apply(lambda x: \n",
    "    True if 'indicador de consumo' in x.lower() else False)\n",
    "\n",
    "\n",
    "data[\"Inmovilizador\"] = data[\"Confort_Inmovilizador\"].apply(lambda x: \n",
    "    True if 'Inmovilizador' in x else False)\n",
    "\n",
    "\n",
    "data[\"Intermitentes_Laterales\"] = data[\"Confort_Intermitentes\"].apply(lambda x:\n",
    "    True if 'laterales' in x else False)\n",
    "\n",
    "\n",
    "data[\"Lavafaros\"] = data[\"Confort_Lavafaros\"].apply(lambda x:\n",
    "    True if 'Lavafaros' in x else False)\n",
    "\n",
    "\n",
    "data[\"Sensor_Lluvia\"] = data[\"Confort_Limpiaparabrisas\"].apply(lambda x: \n",
    "    True if 'sensor de lluvia' in x.lower() else False)\n",
    "data[\"Intermitencia_Automatica\"] = data[\"Confort_Limpiaparabrisas\"].apply(lambda x: \n",
    "    True if 'intermitencia automática' in x.lower() else False)\n",
    "\n",
    "\n",
    "data[\"Luces_Lectura\"] = data[\"Confort_Luces\"].apply(lambda x: \n",
    "    True if 'luces de lectura' in x.lower() else False)\n",
    "data[\"Luces_Antiniebla\"] = data[\"Confort_Luces\"].apply(lambda x: \n",
    "    True if 'luces antiniebla' in x.lower() else False)\n",
    "data[\"Luces_Cortesía\"] = data[\"Confort_Luces\"].apply(lambda x: \n",
    "    True if 'luces de cortesía' in x.lower() else False)\n",
    "data[\"Luces_Laterales\"] = data[\"Confort_Luces\"].apply(lambda x: \n",
    "    True if 'luces laterales maniobras' in x.lower() else False)\n",
    "\n",
    "\n",
    "data[\"Memoria_Asientos\"] = data[\"Confort_Memoria\"].apply(lambda x: \n",
    "    True if 'posición' in x else False)\n",
    "\n",
    "\n",
    "data[\"Techo_Electrico\"] = data[\"Confort_Techo\"].apply(lambda x: \n",
    "    True if 'eléctrico' in x.lower() else False)\n",
    "data[\"Techo_Inclinable\"] = data[\"Confort_Techo\"].apply(lambda x: \n",
    "    True if 'inclinable' in x.lower() else False)\n",
    "data[\"Techo_Deslizante\"] = data[\"Confort_Techo\"].apply(lambda x: \n",
    "    True if 'deslizante' in x.lower() else False)\n",
    "data[\"Control_Remoto\"] = data[\"Confort_Techo\"].apply(lambda x: \n",
    "    True if 'control remoto' in x.lower() else False)\n",
    "\n",
    "data[\"Testigo_Cinturones\"] = data[\"Confort_Testigo\"].apply(lambda x: \n",
    "    True if 'testigo de cinturones' in x.lower() else False)\n",
    "\n",
    "data[\"Numero_Testigos\"] = data[\"Confort_Testigo\"].apply(extraer_numero_tcinturones)\n",
    "\n",
    "\n",
    "# Feed para el modelo NLP\n",
    "data[\"Confort_Volante_Descripción\"] = data[\"Confort_Volante\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminar todas las columas con descripciones iniciales\n",
    "for col in confort_columns: \n",
    "    data.drop(columns=col, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Acabado Interior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "acabado_interior_columns = find_dirty_columns(\"Acabado Interior\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "acabado_interior_columns.remove(\"Acabado Interior_Asientos\")\n",
    "data.drop(columns=\"Acabado Interior_Asientos\", inplace=True)\n",
    "\n",
    "#for x in acabado_interior_columns: print(x)\n",
    "#data[acabado_interior_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lingf\\AppData\\Local\\Temp\\ipykernel_17108\\950979874.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"sports_pedals\"] = data[\"Acabado Interior_Pedales\"].apply(convert_sports_pedals)\n",
      "C:\\Users\\lingf\\AppData\\Local\\Temp\\ipykernel_17108\\950979874.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"interior_clock\"] = data[\"Acabado Interior_Reloj\"].apply(convert_interior_clock)\n"
     ]
    }
   ],
   "source": [
    "# Definir funciones personalizadas para la conversión\n",
    "def convert_sports_pedals(value):\n",
    "    if value == \"['Pedales deportivos']\":\n",
    "        return True\n",
    "    elif value == 'no tiene':\n",
    "        return False\n",
    "    else:\n",
    "        return None  # Por si hay otros valores\n",
    "\n",
    "def convert_interior_clock(value):\n",
    "    if value == \"['Reloj analógico']\":\n",
    "        return 'analogico'\n",
    "    elif value == \"['Reloj digital']\":\n",
    "        return 'digital'\n",
    "    elif value == \"['Reloj']\":\n",
    "        return 'regular'\n",
    "    elif value == \"no tiene\":\n",
    "        return 'no tiene'\n",
    "    else:\n",
    "        return None  # Por si hay otros valores\n",
    "\n",
    "# Aplicar las funciones a las columnas correspondientes\n",
    "data[\"sports_pedals\"] = data[\"Acabado Interior_Pedales\"].apply(convert_sports_pedals)\n",
    "data[\"interior_clock\"] = data[\"Acabado Interior_Reloj\"].apply(convert_interior_clock)\n",
    "\n",
    "#check_unique_values(\"sports_pedals\")\n",
    "#check_unique_values(\"interior_clock\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: arm_suppport_front\n",
      "Tiene: 117241\n",
      "abatible: 98\n",
      "ajustable: 1\n",
      "caja integrada: 4238\n",
      "no tiene: 43859\n",
      "NA: 0\n",
      "Column: arm_suppport_back\n",
      "Tiene: 64993\n",
      "abatible: 5\n",
      "acceso maletero: 406\n",
      "ajustable: 2\n",
      "caja integrada: 1415\n",
      "caja integrada acceso maletero: 559\n",
      "no tiene: 98057\n",
      "NA: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def process_arm_suppport_front(phrases: list) -> str:\n",
    "    stop_words = set(stopwords.words('spanish'))\n",
    "    stop_words.add(\",\")\n",
    "    text = \" # \".join(phrases)\n",
    "    if not ('delantero' in text): return (\"no tiene\")\n",
    "    text = [word for word in text.split() if word not in stop_words]\n",
    "    if '#' in text: \n",
    "        ret = \" \".join( text[ (text.index('delantero')+1):text.index('#')] )\n",
    "        return \"Tiene\" if len(ret) == 0 else ret\n",
    "    else: \n",
    "        ret = \" \".join( text[(text.index('delantero')+1):len(text)] ) \n",
    "        return \"Tiene\" if len(ret) == 0 else ret\n",
    "\n",
    "def process_arm_suppport_back(phrases: list) -> str:\n",
    "    stop_words = set(stopwords.words('spanish'))\n",
    "    stop_words.add(\",\")\n",
    "    text = \" # \".join(phrases)\n",
    "    if not ('trasero' in text): return (\"no tiene\")\n",
    "\n",
    "    text = [word for word in text.split() if word not in stop_words]\n",
    "\n",
    "    ret = \" \".join( text[(text.index('trasero')+1):len(text)] ) \n",
    "    return \"Tiene\" if len(ret) == 0 else ret \n",
    "\n",
    "arm_suppport_front = data[\"Acabado Interior_Apoyabrazos\"].apply(lambda x: x if x == 'no tiene' else process_arm_suppport_front(eval(x)) )\n",
    "arm_suppport_back = data[\"Acabado Interior_Apoyabrazos\"].apply(lambda x: x if x == 'no tiene' else process_arm_suppport_back(eval(x)) )\n",
    "\n",
    "data = pd.concat([data, arm_suppport_front.rename(\"arm_suppport_front\"), arm_suppport_back.rename(\"arm_suppport_back\")], axis=1)\n",
    "\n",
    "check_unique_values(\"arm_suppport_front\")\n",
    "check_unique_values(\"arm_suppport_back\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_seat_description(phrases: list) -> str: return \". \".join(phrases)\n",
    "\n",
    "data[\"seat_description\"] = data[\"Acabado Interior_Asiento\"].apply( lambda x: x if x == 'no tiene' else process_seat_description(eval(x)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Acabado Interior_Uno\"] = data[\"Acabado Interior_Uno\"].apply( lambda x: \"['no tiene']\" if x == 'no tiene' else x )\n",
    "data[\"Acabado Interior_Dos\"] = data[\"Acabado Interior_Dos\"].apply( lambda x: \"['no tiene']\" if x == 'no tiene' else x )\n",
    "data[\"Acabado Interior_Tres\"] = data[\"Acabado Interior_Tres\"].apply( lambda x: \"['no tiene']\" if x == 'no tiene' else x )\n",
    "data[\"Acabado Interior_Reposacabezas\"] = data[\"Acabado Interior_Reposacabezas\"].apply( lambda x: \"['no tiene']\" if x == 'no tiene' else x )\n",
    "\n",
    "data[\"Acabado Interior_Uno\"] = data[\"Acabado Interior_Uno\"].apply(ast.literal_eval)\n",
    "data[\"Acabado Interior_Dos\"] = data[\"Acabado Interior_Dos\"].apply(ast.literal_eval)\n",
    "data[\"Acabado Interior_Tres\"] = data[\"Acabado Interior_Tres\"].apply(ast.literal_eval)\n",
    "data[\"Acabado Interior_Reposacabezas\"] = data[\"Acabado Interior_Reposacabezas\"].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['head_supporter'] = data.apply(\n",
    "    lambda row: \". \".join(\n",
    "        remove_duplicates(row[\"Acabado Interior_Uno\"] + row[\"Acabado Interior_Dos\"] + row[\"Acabado Interior_Tres\"] + row[\"Acabado Interior_Reposacabezas\"], 'no tiene')\n",
    "    ), \n",
    "    axis=1)\n",
    "#check_unique_values(\"head_supporter\")\n",
    "\n",
    "for col in acabado_interior_columns: data.drop(columns= col, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Acabado Exterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopw = frozenset(stopwords.words('spanish')) | {\",\"}\n",
    "\n",
    "def cleanTry(phrases: list) -> str:\n",
    "    if not phrases:\n",
    "        return \"no tiene\"\n",
    "    \n",
    "    # Join phrases into a single string and clean punctuation\n",
    "    text = phrases\n",
    "    \n",
    "    # Remove stopwords efficiently\n",
    "    text = [word for word in text.split() if word.lower() not in stopw]\n",
    "\n",
    "    # Return cleaned text or \"no tiene\" if empty\n",
    "    return \"no tiene\" if len(text) == 0 else \" \".join(text)\n",
    "\n",
    "def extract_diameter(text):\n",
    "    # Regular expression to find the diameter (e.g., '17 pulgadas diámetro')\n",
    "    match = re.search(r'(\\d+(?:,\\d+)?)\\s*pulgadas\\s*diámetro', text)\n",
    "    if match:\n",
    "        # Return the matched diameter (convert from string to float, replacing ',' with '.')\n",
    "        return (float(match.group(1).replace(',', '.'))*2.54)  # Convert inches to centimeters\n",
    "    else:\n",
    "        return \"no tiene\"  # Return a default value if no diameter is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=[\"Acabado Exterior_Maletero\",\"Acabado Exterior_Pasos\",\"Acabado Exterior_Maletero\",\"Acabado Exterior_Defensa\",\"Acabado Exterior_Guardabarros\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "acabado_exterior_columns = find_dirty_columns(\"Acabado Exterior\")\n",
    "\n",
    "data[acabado_exterior_columns] = data[acabado_exterior_columns].apply(lambda col: col.apply(lambda x: cleanTry(x) if x != 'no tiene' else x))\n",
    "\n",
    "data[\"Llantas_Diametro_cm\"] = data[\"Acabado Exterior_Llantas\"].apply(lambda x: extract_diameter(x))\n",
    "#for x in acabado_exterior_columns: \n",
    "    #print(x)\n",
    "    #print(\"Descripcion --------------------------\")\n",
    "    #print(data[x].describe())\n",
    "    #print(\"Counts--------------------------------\")\n",
    "    #print(data[x].value_counts())\n",
    "    #print(\"CleanTry------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Electronic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                   Gasolina\n",
      "1                   Gasolina\n",
      "2                   Gasolina\n",
      "3                  Eléctrico\n",
      "4                    Híbrido\n",
      "                 ...        \n",
      "165432                Diésel\n",
      "165433              Gasolina\n",
      "165434               Híbrido\n",
      "165435    Híbrido enchufable\n",
      "165436              Gasolina\n",
      "Name: fuelType, Length: 165437, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data[\"fuelType\"])\n",
    "#check_unique_values(\"fuelType\") Pone que hay un float en esa columna, solucionalo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m start_row \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(df):\n\u001b[0;32m     21\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[43msplit_dataframe_to_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_file_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[43], line 12\u001b[0m, in \u001b[0;36msplit_dataframe_to_csv\u001b[1;34m(df, max_file_size, base_filename)\u001b[0m\n\u001b[0;32m     10\u001b[0m chunk \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[start_row:end_row]\n\u001b[0;32m     11\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_part\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 12\u001b[0m \u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mgetsize(filename) \u001b[38;5;241m>\u001b[39m max_file_size:\n\u001b[0;32m     14\u001b[0m     chunk_size \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\lingf\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lingf\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3965\u001b[0m )\n\u001b[1;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lingf\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\lingf\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:270\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[1;32m--> 270\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lingf\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:275\u001b[0m, in \u001b[0;36mCSVFormatter._save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_need_to_save_header:\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_header()\n\u001b[1;32m--> 275\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lingf\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:313\u001b[0m, in \u001b[0;36mCSVFormatter._save_body\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m end_i:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 313\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_i\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lingf\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:320\u001b[0m, in \u001b[0;36mCSVFormatter._save_chunk\u001b[1;34m(self, start_i, end_i)\u001b[0m\n\u001b[0;32m    317\u001b[0m slicer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(start_i, end_i)\n\u001b[0;32m    318\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc[slicer]\n\u001b[1;32m--> 320\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_values_for_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_number_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(res\u001b[38;5;241m.\u001b[39m_iter_column_arrays())\n\u001b[0;32m    323\u001b[0m ix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_index[slicer]\u001b[38;5;241m.\u001b[39m_get_values_for_csv(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_number_format)\n",
      "File \u001b[1;32mc:\\Users\\lingf\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:1410\u001b[0m, in \u001b[0;36mDataFrame._get_values_for_csv\u001b[1;34m(self, float_format, date_format, decimal, na_rep, quoting)\u001b[0m\n\u001b[0;32m   1400\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_values_for_csv\u001b[39m(\n\u001b[0;32m   1401\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1402\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1408\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m   1409\u001b[0m     \u001b[38;5;66;03m# helper used by to_csv\u001b[39;00m\n\u001b[1;32m-> 1410\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_values_for_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfloat_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfloat_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_rep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_rep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1417\u001b[0m     \u001b[38;5;66;03m# error: Incompatible return value type (got \"DataFrame\", expected \"Self\")\u001b[39;00m\n\u001b[0;32m   1418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(mgr, axes\u001b[38;5;241m=\u001b[39mmgr\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32mc:\\Users\\lingf\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:466\u001b[0m, in \u001b[0;36mBaseBlockManager.get_values_for_csv\u001b[1;34m(self, float_format, date_format, decimal, na_rep, quoting)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_values_for_csv\u001b[39m(\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, float_format, date_format, decimal, na_rep: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m\"\u001b[39m, quoting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    461\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m    462\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;124;03m    Convert values to native types (strings / python objects) that are used\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;124;03m    in formatting (repr / csv).\u001b[39;00m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 466\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget_values_for_csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_rep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_rep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfloat_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfloat_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lingf\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32mc:\\Users\\lingf\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:780\u001b[0m, in \u001b[0;36mBlock.get_values_for_csv\u001b[1;34m(self, float_format, date_format, decimal, na_rep, quoting)\u001b[0m\n\u001b[0;32m    775\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_values_for_csv\u001b[39m(\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, float_format, date_format, decimal, na_rep: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m\"\u001b[39m, quoting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    778\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Block:\n\u001b[0;32m    779\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"convert to our native types format\"\"\"\u001b[39;00m\n\u001b[1;32m--> 780\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mget_values_for_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    781\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_rep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_rep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    783\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    784\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfloat_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfloat_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    788\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_block(result)\n",
      "File \u001b[1;32mc:\\Users\\lingf\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7864\u001b[0m, in \u001b[0;36mget_values_for_csv\u001b[1;34m(values, date_format, na_rep, quoting, float_format, decimal)\u001b[0m\n\u001b[0;32m   7861\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_values\n\u001b[0;32m   7863\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 7864\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[43misna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   7865\u001b[0m     itemsize \u001b[38;5;241m=\u001b[39m writers\u001b[38;5;241m.\u001b[39mword_len(na_rep)\n\u001b[0;32m   7867\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m _dtype_obj \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quoting \u001b[38;5;129;01mand\u001b[39;00m itemsize:\n",
      "File \u001b[1;32mc:\\Users\\lingf\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\dtypes\\missing.py:178\u001b[0m, in \u001b[0;36misna\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21misna\u001b[39m(obj: \u001b[38;5;28mobject\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mbool_] \u001b[38;5;241m|\u001b[39m NDFrame:\n\u001b[0;32m    102\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03m    Detect missing values for an array-like object.\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;124;03m    Name: 1, dtype: bool\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_isna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lingf\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\dtypes\\missing.py:207\u001b[0m, in \u001b[0;36m_isna\u001b[1;34m(obj, inf_as_na)\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (np\u001b[38;5;241m.\u001b[39mndarray, ABCExtensionArray)):\n\u001b[1;32m--> 207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_isna_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minf_as_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minf_as_na\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, ABCIndex):\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;66;03m# Try to use cached isna, which also short-circuits for integer dtypes\u001b[39;00m\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;66;03m#  and avoids materializing RangeIndex._values\u001b[39;00m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_can_hold_na:\n",
      "File \u001b[1;32mc:\\Users\\lingf\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\dtypes\\missing.py:300\u001b[0m, in \u001b[0;36m_isna_array\u001b[1;34m(values, inf_as_na)\u001b[0m\n\u001b[0;32m    298\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39mnp\u001b[38;5;241m.\u001b[39misfinite(values)\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 300\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misnan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_file_size = 100 * 1024 * 1024\n",
    "output_folder = \"NLP/test_data\"\n",
    "def split_dataframe_to_csv(df, max_file_size, base_filename):\n",
    "    file_index = 1\n",
    "    chunk_size = len(df) // 7 \n",
    "    while chunk_size > 0:\n",
    "        start_row = 0\n",
    "        while start_row < len(df):\n",
    "            end_row = start_row + chunk_size\n",
    "            chunk = df.iloc[start_row:end_row]\n",
    "            filename = f\"{output_folder}/{base_filename}_part{file_index}.csv\"\n",
    "            chunk.to_csv(filename, index=False)\n",
    "            if os.path.getsize(filename) > max_file_size:\n",
    "                chunk_size //= 2\n",
    "                os.remove(filename)\n",
    "            else:\n",
    "                start_row = end_row\n",
    "                file_index += 1\n",
    "\n",
    "        if start_row >= len(df):\n",
    "            break\n",
    "\n",
    "split_dataframe_to_csv(data, max_file_size, base_filename=\"test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
